
线性代数(正交矩阵，矩阵的秩，特征值特征向量等关键概念)

概率论(独立的概念，一些分布，大数定理等)


# 计算机常识
## P=NP？
-  **P类问题**：指的是那些可以在多项式时间（Polynomial Time）内解决的问题。多项式时间是指算法所需的时间与输入规模n的关系是n的某个多项式函数，比如n^2、n^3等。这类问题通常被认为是"容易"解决的。
- **NP类问题**：指的是那些可以在多项式时间内验证一个解的问题。也就是说，如果有人给出了一个解，我们可以在多项式时间内检查这个解是否正确。但并不保证我们能在多项式时间内找到这个解。NP类问题包括了P类问题，因为一个能在多项式时间内解决的问题，自然也能在多项式时间内验证其解
- **P=NP问题** 的核心是询问：是否所有能在多项式时间内验证解的问题（NP问题），实际上也能在多项式时间内找到解（即它们也是P问题）？
## 图灵机

图灵机（Turing Machine）是计算机科学中的一个理论模型，由英国数学家艾伦·图灵（Alan Turing）在1936年提出。图灵机是一个抽象的计算设备，它定义了一种通用的计算模型，可以用来模拟任何算法执行的过程。

图灵机的通用性表明，只要有足够的资源和时间，理论上可以用图灵机模拟任何现代计算机的行为。
### 1. 基本部分

1. **无限长的纸带**：这个纸带被分成一个个小方格，每个方格可以写入一个符号（比如0或1，或者任何其他字符）。

2. **读写头**：图灵机有一个可以读取和写入纸带上方格内容的读写头。

3. **状态寄存器**：图灵机有一个状态寄存器，用来存储图灵机当前的状态。图灵机有一组有限的状态，包括一个开始状态和一个或多个结束状态。

4. **控制规则**：控制规则（也称为转移函数或程序）定义了图灵机在特定状态下读取到某个符号时应该执行的操作，包括写入一个符号、移动读写头（向左或向右）、以及改变状态。

### 2. 操作步骤 

1. 图灵机从初始状态开始，读写头位于纸带的起始位置。

2. 根据当前状态和读写头下方的符号，图灵机查找控制规则，执行相应的操作。

3. 操作可能包括在当前方格写入一个新符号、移动读写头、以及改变状态。

4. 重复上述步骤，直到图灵机进入一个结束状态，此时计算完成。

### 图灵机停机问题

并非所有问题都能通过算法来解决。

停机问题是第一个被证明为不可判定的问题，它对计算机科学和逻辑学产生了深远的影响，表明了计算能力的局限性。

**图灵停机问题** 是由艾伦·图灵在1936年提出的一个不可判定问题。停机问题询问是否存在一个通用的算法，能够判定任意给定的图灵机在给定输入下是否会停止（即最终达到一个结束状态），还是永远运行下去（即进入一个无限循环）。

图灵通过证明不存在这样的通用算法来回答这个问题。他的证明使用了反证法，假设存在一个算法H，可以判定任意图灵机在任意输入下是否停机。然后，图灵构造了一个新的图灵机D，它使用假设的算法H作为子程序。图灵机D的行为是：如果H判定某个图灵机T在输入I下会停机，那么D就进入一个无限循环；如果H判定T在I下不会停机，那么D就停机。

接下来，图灵让D评估自己，即D在输入自己的描述上运行。这时就会出现悖论：如果D判定自己在自己的输入上会停机，那么根据D的定义，它应该进入无限循环，这与判定结果矛盾；如果D判定自己不会停机，那么它应该停机，这也与判定结果矛盾。因此，假设的算法H不可能存在，停机问题是不可判定的。

# 线性代数
## 伴随矩阵和逆
[请问伴随矩阵在几何空间的意义是什么？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/301361922/answer/951628967)
## 线性空间
对于一个向量集合，若该集合内的向量满足加法和数乘封闭性，则该向量集合构成线性空间，也即向量空间
加法、数乘、0、1
## 什么是线性相关？
**矢量空间的一组元素中，若没有矢量可用有限个其他矢量的线性组合所表示**，则称为线性无关或线性独立 (linearly independent)，反之称为线性相关 (linearly dependent)。
也就是说，冗余的存在意味着线性相关。
## 基变换
- 大家的原点相同，（0，0）
- 不同的基方向和单位间距不同
使用不同的基向量会怎么样？
![[Pasted image 20240523192742.png]]
该矩阵将我们的直角坐标系，转换到了另一个基上
![[Pasted image 20240523193039.png]]
## 叉积？
结果是一个向量，长度是计算得到的面积，右手法则确定方向。有方向。算面积其实就是行列式的方式。
![[Pasted image 20240523190730.png]]这个公式计算的结果就是向量的方向
![[Pasted image 20240523190150.png]]
![[Pasted image 20240523190030.png]]
![[Pasted image 20240523190119.png]]

## 点积和对偶性？
- 点积：投影，对称的。为什么？对偶性。
- ![[Pasted image 20240523185133.png]]
- ![[Pasted image 20240523185148.png]]
- 对偶性：一个多维空间到数轴的线性变换，总是对应那个空间中的一个向量。对其来说，应用线性变换和向量点乘等价。
## 非方阵？
![[Pasted image 20240523184933.png]]

## 矩阵的秩是什么，有什么意义？
- 变换后，空间的维数（列空间的维数）
- 矩阵中线性无关的行向量或列向量的最大个数。
## 列空间是什么？
矩阵A所描述变换后，所有可能的输出向量Av构成的集合
## 线性变换的定义
- 直线仍然保持直线
- 原点保持不变
## 矩阵的乘积
意义就是两个线性变换依次作用
![[Pasted image 20240523182431.png]]
## 矩阵的几何意义？
- 线性变换：可以看作一种线性变换的表示，比如旋转、缩放、投影等
- 基变换：在不同的基下，同一个向量的坐标表示是不同的。
## 行列式是什么，意义？
![[Pasted image 20240522172310.png]]
- 行列式本质上是一个函数
- n维空间中，描述的是一个线性变换对“体积”造成的影响
## 矩阵运算为什么不满足交换律？

矩阵可以看作是线性变换的表示。当我们将一个矩阵 (A) 作用于一个向量 (v) 时，可以理解为对 (v) 进行了一次线性变换。如果再对变换后的结果应用另一个矩阵 (B)，则相当于进行了两次线性变换。

1. **矩阵 (A) 的变换**：假设 (A) 是一个旋转矩阵，它将向量 (v) 旋转一个角度。
2. **矩阵 (B) 的变换**：假设 (B) 是一个缩放矩阵，它对向量进行缩放。

- 如果先进行旋转 (A) 再进行缩放 (B)，即 (B(Av))，这表示先旋转向量，然后对旋转后的向量进行缩放。
- 如果先进行缩放 (B) 再进行旋转 (A)，即 (A(Bv))，这表示先缩放向量，然后对缩放后的向量进行旋转。
## 矩阵的逆(inverse)的意义？
![[Pasted image 20240523183920.png]]
- 当A的行列式（变换）不等于零（不压缩维度）：有唯一向量x满足
- 等于零：
	- 如果向量v是矩阵A的列空间的元素，即v可以表示为A的列向量的线性组合，那么方程组Ax=v有解。这是因为在这种情况下，存在至少一个向量x，使得Ax等于v。
	- 如果向量v不是矩阵A的列空间的元素，那么方程组Ax=v无解。这是因为在这种情况下，不存在向量x，使得Ax等于v。
矩阵的逆在数学上有着非常重要的意义。如果一个矩阵$A$有逆矩阵$A^{-1}$，那么这两个矩阵的乘积是单位矩阵$I$，即$AA^{-1} = A^{-1}A = I$。单位矩阵在矩阵乘法中起着类似于实数中的数字1的作用，任何矩阵与单位矩阵相乘都等于其本身。

从几何的角度来看，矩阵代表了一种线性变换，而其逆矩阵则代表了这种变换的逆操作。例如，如果一个矩阵代表了一个旋转操作，那么其逆矩阵就代表了一个反向的旋转操作；如果一个矩阵代表了一个缩放操作，那么其逆矩阵就代表了一个反向的缩放操作。因此，矩阵的逆在解决线性方程组，特别是在解决线性代数问题中有着重要的应用。

需要注意的是，并非所有的矩阵都有逆矩阵。只有当矩阵是方阵（即行数和列数相等），并且其行列式不为0时，这个矩阵才有逆矩阵。如果一个矩阵没有逆矩阵，我们就说这个矩阵是奇异的或者不可逆的。

## 增广矩阵

![[Pasted image 20240531211607.png]]

## 正交矩阵
- 正交矩阵：转置等于逆阵 的矩阵
## 什么是正定矩阵？

从几何的角度来看，正定矩阵**代表了一种特殊的线性变换**，这种变换保持了向量的"方向"。更具体地说，**如果你将一个向量看作是从原点出发的箭头，那么正定矩阵的线性变换就是将这个箭头"拉长"或"压缩"，但不改变它的方向。**

这就是为什么在最优化问题中，正定矩阵通常与"凸"的概念相关联：在凸优化问题中，目标函数通常是一个正定矩阵定义的二次型，这保证了目标函数有一个全局最小值。

需要注意的是，正定矩阵必须是对称的，但并非所有对称矩阵都是正定的。一个对称矩阵是正定的，当且仅当它的所有特征值都是正的。

## 凸优化和正定矩阵

- 实对称矩阵：有n阶矩阵A，其矩阵的元素都为实数，且矩阵A的转置等于其本身
- 实对称矩阵 𝐴 是正定矩阵等价于 𝐴 的特征值全是正数.
	- (1) 𝐴 是正定矩阵;
	- (2) 𝐴 的所有主子式都是正数;
	- (3) 𝐴 的各级顺序主子式都是正数.

在优化问题中，我们通常希望找到一个函数的最小值或最大值。在凸优化问题中，这个函数被称为目标函数，它具有一个特殊的性质：任何两点之间的线段都在函数的图像之上。这就是所谓的“凸性”。

在许多凸优化问题中，目标函数是一个二次型，也就是说，它可以写成$x^TAx + b^Tx + c$的形式，其中$x$是我们要优化的变量，$A$是一个正定矩阵，$b$是一个向量，$c$是一个常数。这样的函数被称为二次型。

正定矩阵在这里起到了关键的作用。由于正定矩阵的性质，二次型函数在所有方向上都是“向上开口”的，也就是说，它在某个点达到最小值。这个点就是我们要找的最优解。因此，正定矩阵定义的二次型函数在凸优化问题中非常常见，因为它们保证了存在一个全局最小值，这使得问题可以被有效地解决。

**总的来说，这句话的意思是：在凸优化问题中，我们通常要最小化的函数（目标函数）是由正定矩阵定义的二次型函数，这样的函数具有良好的性质，使得问题可以被有效地解决。**

## 相似矩阵
- 相似矩阵：对于矩阵 𝐴 和 𝐵 ，当且仅当存在一个可逆矩阵 𝑃 ，使得 𝑃−1𝐴𝑃=𝐵 ，则称 𝐴 和 𝐵 相似。（判断是否相似：特征值相等、行列式相等、迹相等、秩相等，但反之不一定成立）
## 特征向量与特征值？
特征值：eigen-value
特征向量：eigen-vector
- 矩阵的特征向量，也就是对于该矩阵代表的变换，该向量只是进行了拉伸或压缩，方向并没有发生变化。
- 而拉伸或压缩的值，就是其特征值。
![[Pasted image 20240522173218.png]]
- 如何求解？
	- ![[Pasted image 20240522173552.png]]
	- 只有该矩阵代表的变换降维，才能使其与非零向量v乘积为0向量
	- 也就是det(A-lamda I) = 0
	- ![[Pasted image 20240522173803.png]]
# 离散数学

# 概率论与数理统计

## 协方差和相关系数
协方差：反映两个随机变量之间的联合变动程度，衡量两个变量的线性相关性程度。
![[Pasted image 20240531210753.png]]![[Pasted image 20240531211000.png]]
![[Pasted image 20240531211100.png]]
相关系数：研究变量之间线性相关程度的量，相当于是无量纲的协方差，将协方差进行了归一化。

## 独立性和相关性
独立性：一个事件的发生不会影响另一个事件的发生。
（线性）相关性：两个事件不存在线性关系，但不排除其他关系存在。
## 变量和随机变量
变量是指可变的量，而随机变量的取值不仅可变，还在此基础上对每一个取值赋予了一个取到的概率
## 假设检验的定义，两类错误
定义：先对总体参数或总体分布函数的形式进行某种假设，然后由抽样结果对假设是否成立进行推断。

两类错误：（1）弃真：假设正确但被舍弃；（2）留伪：假设错误但被接受

## 马尔可夫过程
- 马尔可夫过程：对于**随机过程中的随机变量序列**而言，当前时刻的状态**只与上一时刻的状态有关**，与更早的时刻无关。满足该条件的随机过程叫马尔可夫过程。
	- **随机过程**：随着时间或空间变化的一组随机变量，是一个随机变量的集合，索引下标为时间或空间的位置。

## 概率论和数理统计的关系

概率论关注的是结构和映射，以及他们的性质和关系。它是已知一个数据的产生过程，来对观测数据进行推测。

数理统计关注的是数据和模型，它是已知观测数据，对数据的产生过程进行推测。
## 联合概率密度和边缘概率密度

联合概率：基于**两个或多个随机变量及其相互作用**的样本空间的概率。

边缘概率：多维随机变量的样本空间中，某一个或多个随机变量构成的子空间的概率。在联合概率的基础上，固定若干个随机变量的取值便得到边缘概率。

## 概率密度函数，概率分布函数
函数值表示随机变量取到该值的可能性大小，但无法表示准确概率。可以利用定积分求解落在某个区间内的概率大小。
## 全概率公式
产生某结果概率，转化为各种可能原因产生该结果概率的和
![[Pasted image 20240531193353.png]]
## 贝叶斯定律
根据结果，计算是某个因素的概率
![[Pasted image 20240531193434.png]]
## 无偏性，有效性，一致性
- 无偏性：估计量的数学期望等于被估计参数的真实值。即无偏估计量只有随机误差而没有系统误差。
	- (1)无偏估计有时并不一定存在。  
	- (2)可估参数的无偏估计往往不唯一。  
	- (3)无偏估计不一定是好估计。
- 有效性：有效性就是看估计量的方差值，方差代表波动，波动越小越有效。
- 一致性：在大样本条件下，估计值接近真实值。
	- (1)无偏不等于一致，无偏是不能得出一致的；
	- (2)无偏描述的有限样本关于真实值的关系，而一致性描述的大数样本的关系。
## 大数定律
- [辛钦](https://baike.baidu.com/item/%E8%BE%9B%E9%92%A6/10238464?fromModule=lemma_inlink)大数定律：常用的大数定律
	- 如果我们有一组独立同分布的随机变量，那么这些随机变量的样本均值将以概率1收敛于这些随机变量的期望值
	- ![[Pasted image 20240522165034.png]]![[Pasted image 20240522165017.png]]
- 切比雪夫大数定理
	- ![[Pasted image 20240522165128.png]]
	- 相互独立的随机变量，分别具有期望和方差，且方差一致有上界，其和的算术平均值与其期望的算术平均值之差，当n趋向于∞时，依概率收敛于0
- 伯努利大数定律
	- 独立重复实验的次数足够多的时候，事件发生的概率无限接近于事件发生的频率除以总次数，即：**用频率估计概率**。
## 中心极限定律
- 随机变量和的分布，趋近于正态分布
	- 独立同分布的中心极限定律。条件：独立同分布，有期望，有方差
	- 拉普拉斯中心极限定律。相当于独立同分布的0-1分布。
	- 李雅普诺夫中心极限定律。独立同分布，期望/方差不管，当满足某个条件，也能近似正态分布。
## 什么是独立？
- 其中一个变量的概率分布不受另一个变量取值的影响
## 什么是同分布？
- 具有相同的概率分布函数。
	- 同分布性意味着两个变量在概率分布上是相同的，但并不意味着它们是独立的。
# 微积分
[保研面试/考研复试数学问题整理（cs/ai 等工科专业） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/567252248)
## 什么是洛必达法则，它有什么用？

## 多元函数求极值？
- （条件极值）拉格朗日乘数法
- 求驻点；对每个驻点，求二阶偏导；通过（海森矩阵）判别式判断
	- [高等数学从入门到入坟——多元函数的极值问题&Hesse矩阵失效的解决办法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/692857686)
	- ![[Pasted image 20240531165327.png]]
## 闭区间连续，开区间可导？
因为函数在闭区间上连续要求左端点右连续、右端点左连续；而函数可导则要求函数在**一点的左右导数均存在且相等**，若为闭区间，则只能验证左端点是否有右导数，右端点是否有左导数，故函数在闭区间的端点处不可导。

中值定理就是函数某点或者函数的某条斜率代替原函数的定理，所以需要闭区间连续开区间可导。
## 梯度、散度、旋度

- 梯度：对于多元标量函数的某个点上的梯度，指的是该函数在该点处的每个维度上的偏导数构成的向量。也称为 ∇ 算子。
- 散度：散度是一个标量，表示在向量场中一点处**通量对体积的变化率**。也就是该点处对一个单位体积来说所穿过的通量，此即为该点处源的强度。
- 旋度：向量，**环量对面积的变化率，也可以称为环量面密度，反映出向量场中某点的环量强度**。
- 
- 通量是单位时间内通过的某个曲面的量
- 散度是通量强度
- 环流量是单位时间内环绕的某个曲线的量
- 旋度是环流量强度

## 连续和一致连续
![[Pasted image 20240531170126.png]]
![[Pasted image 20240531170252.png]]
## 极限的定义？
对于任意 𝜖>0 ，总存在一个正数 𝑁 ，使得 𝑛>𝑁 时， |𝑎𝑛−𝐴|<𝜖 恒成立，则 𝐴 为该数列的极限。
## 牛顿迭代法
[牛顿迭代法_newton-raphson法-CSDN博客](https://blog.csdn.net/le_serein_/article/details/136465351)
- 牛顿迭代法的基本思想是**利用函数的切线来逼近方程的根**。假设我们要求解的方程 𝑓(𝑥)=0 ，从一个初始近似解 𝑥0 开始，我们可以利用函数 𝑓(𝑥) 在 𝑥=𝑥0 处的切线来估计方程的根。切线的斜率为 𝑓′(𝑥0) ，所以切线与 𝑥 轴的交点就是一个**新的近似解**。通过不断**迭代**这个过程，我们可以逼近方程的根。
- 具体来说，牛顿迭代法通过在当前猜测点处对函数进行泰勒级数展开，并取其一阶近似，然后求解这个线性方程来得到下一个猜测点。

局限性
虽然牛顿迭代法在数值计算中被广泛应用，并且通常收敛速度很快，但它也有一些缺点需要考虑：
1.初始值敏感性：牛顿迭代法的收敛性高度依赖于初始近似解的选择。如果初始值选择不当，可能导致迭代发散或者收敛到错误的根。
2.导数计算困难：在某些情况下，计算函数的导数困难比计算函数本身更加困难，尤其是对于复杂的非线性函数。如果导数计算不准确，可能导致迭代结果不稳定或者出现误差。
3.局部收敛性：（重中之重）牛顿迭代法只能保证在某个根的局部收敛，而无法保证全局收敛性。这也佐证了恰当的初始解才会搜索到正确的近似根。
# 操作系统
![[Pasted image 20240512160701.png]]
# 数据结构
## 解释一下什么是时间复杂度；
用来衡量算法执行时间随输入数据规模增长而增长的一个概念。它描述了算法运行时间与问题规模（通常用n表示）之间的关系。
A concept used to measure the growth of algorithm execution time as the size of the input data grows. It describes the relationship between the running time of the algorithm and the scale of the problem, which usually denoted by n.
## 快排最坏时间复杂度为什么是$O(n^2)$，如何优化快排最坏时间复杂度；
- 快速排序（Quick Sort）之所以被称为“快速”，是因为它在**平均情况下的时间复杂度为O(n log n)，在实践中通常比其他同阶时间复杂度的排序算法（如归并排序和堆排序）更快**。
	- 原地排序：不需要额外的存储空间来存储中间结果，这使得它在内存访问上更加高效。相比之下，归并排序需要额外的存储空间来合并子数组，这可能导致更多的内存访问和缓存未命中。
	- 缓存利用：快速排序的分区操作通常涉及连续的内存访问，这有助于更好地利用CPU缓存。而堆排序和归并排序的内存访问模式可能不那么连续，导致缓存利用率较低。
- 平均时间复杂度为 O(n log n)
- 在最坏情况下，每次选择的基准元素都是当前数组的最小或最大元素，导致每次划分只能减少一个元素，而另一个子数组为空。这种情况下，快速排序的时间复杂度为 O(n^2)
	- 最坏情况的一个典型例子是当输入数组已经完全排序或者完全逆序时
- 在平均情况下，快速排序的时间复杂度仍然是 O(n log n)。这是因为即使在一些划分不平衡的情况下，通过随机选择基准元素或使用三数取中等策略，可以大大减少最坏情况的发生概率，使得算法的性能接近最优情况。
#### 2.1 最好情况（平均情况）

在最好的情况下，每次划分都将序列分为两个几乎相等的部分。假设每次都能将序列分为n/2和n/2两部分，那么递归的深度就是log n，每一层的总操作数是n（因为每一层都需要遍历所有的元素）。因此，最好的情况下，时间复杂度为O(n log n)。

#### 2.2 最坏情况

在最坏的情况下，即每次划分都将序列分为0和n-1两部分（例如，序列已经有序或逆序），这样递归的深度就变成了n，每一层的操作数仍然是n。因此，最坏情况下的时间复杂度为O(n^2)。

#### 2.3 平均情况

平均情况下，快速排序的时间复杂度仍然是O(n log n)。这是因为，即使在最坏的情况下，快速排序的性能也可以通过随机选择基准元素来改善，从而使得每次划分都接近平均分配。
## 红黑树
- 一种二叉查找树，有二叉查找树的性质
		- 根黑色，外（叶子）结点黑色
		- 红色结点的孩子为黑色
		- 任意节点到外结点的路径上，黑色结点数目相同
		- 黑高度：从当前节点到外结点上的黑节点数量
	- 性质
		- 黑平衡
		- 不会有连续两个红色节点
		- 任意一个结点的左右子树高度最多差两倍
		- 平均和最坏高度 O logn，插入删除查找的平均和最坏均是 Ologn
		- 旋转只需要 O 1次
## 最小生成树和最短路径
- Prim算法
	- 考虑点集合，能到达的最近的不在集合中的点，加入集合
	- **朴素实现**：使用邻接矩阵表示图，每次查找最小边需要遍历所有边，时间复杂度为 𝑂(𝑉2)，其中 𝑉 是顶点数。
	- **使用最小堆**：使用邻接表和最小堆（优先队列）来优化查找最小边的过程，时间复杂度为 𝑂((𝑉+𝐸)log⁡𝑉)，其中 𝐸 是边数。如果图是稠密的，即 𝐸=Θ(𝑉2，则时间复杂度为 𝑂(𝑉2log⁡𝑉)。如果图是稀疏的，即 𝐸=𝑂(𝑉)，则时间复杂度为 𝑂(𝑉log⁡𝑉)。
- Kruskal算法
	- 边排序，依次加入，不形成回路。若形成回路跳过
	- **排序边**：首先需要对所有边进行排序，时间复杂度为 𝑂(𝐸log⁡𝐸)，由于 𝐸 最多为 𝑉2，所以这个步骤的时间复杂度可以简化为 𝑂(𝐸log⁡𝑉)。
- 散列表
	- **平均查找复杂度**：在理想情况下，即哈希函数能够将元素均匀地分布到散列表的各个位置上，散列表的查找复杂度为 𝑂(1)。这意味着无论散列表中有多少元素，查找一个元素所需的时间都是常数时间。
- 最短路径
	- Dijkstra算法为什么不能用于负权图
		- Dijkstra算法是贪心算法，大概前提是，从当前的所有可能中就能找到全局的最优解，而负权图不满足这个条件
		- 可能有一条负权边，其一个端点不在集合中，另一个端点在集合中，而dijkstra不会考虑到这条边（能够使已经加入集合的点路径更短）
	- 堆优化的Dijkstra算法
```C++
// Dijkstra算法函数
vector<int> dijkstra(vector<vector<Edge>>& graph, int start) {
    int n = graph.size();
    vector<int> dist(n, numeric_limits<int>::max()); // 初始化距离为无穷大
    priority_queue<pair<int, int>, vector<pair<int, int>>, Compare> pq; // 优先队列

    dist[start] = 0; // 起点到起点的距离为0
    pq.push(make_pair(start, 0)); // 将起点加入优先队列

    while (!pq.empty()) {
        int u = pq.top().first; // 取出距离最小的顶点
        pq.pop();

        for (Edge& edge : graph[u]) { // 遍历所有相邻的边
            int v = edge.to;
            int weight = edge.weight;

            // 如果通过当前顶点可以找到更短的路径，则更新距离并将顶点加入优先队列
            if (dist[u] + weight < dist[v]) {
                dist[v] = dist[u] + weight;
                pq.push(make_pair(v, dist[v]));
            }
        }
    }

    return dist;
}
```
- 用一个priority_queue维护pair(点，距离)，每次取出来一个点，看其邻边，如果能缩短到邻边点的距离则更新，且加入堆中。
- 对于没有负权边的情况，没有问题
- 有负权边的情况，如图![[Pasted image 20240530011908.png]]
	- 此时(C,9)和(D,10)在队列中，但是B更新为2后，又加入了(C,7)和(D,8)，此时dist\[C]=7，dist\[D]=8，堆中还有(C,9),(D,10)，按照算法，取出C,D,C,D，其实也没有问题，就是多取出来了一次，而且也没有用到取出pair的second，也就是放入时刻的距离，而是直接使用dist，因此我觉得是可以的。（要么直接使用一个数组记录该点是否在队列中，那就有点像SPFA了）
		- 思考了一下，此时SPFA和堆优化dijkstra的区别就是，dijkstra用堆且堆中记录(点，加入时刻的dist)，而SPFA用队列，记录(点)
		- dijkstra的问题就是可能会把同一个点先后状态加入多次，而只需要加入这个判断就可以解决![[Pasted image 20240530013046.png]]

	- Bellman-Ford为什么循环n-1次
```C++
// 对每条边进行V-1次松弛操作
    for (int i = 1; i <= V - 1; i++) {
        for (int j = 0; j < E; j++) {
            int u = graph.edges[j].src;
            int v = graph.edges[j].dest;
            int weight = graph.edges[j].weight;
            if (dist[u] != INT_MAX && dist[u] + weight < dist[v])
                dist[v] = dist[u] + weight;
        }
    }

    // 检查负权重环
    for (int i = 0; i < E; i++) {
        int u = graph.edges[i].src;
        int v = graph.edges[i].dest;
        int weight = graph.edges[i].weight;
        if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) {
            cout << "Graph contains negative weight cycle" << endl;
            return;
        }
    }
```
- 图有n个点，又不能有回路，所以最短路径最多n-1边
- SPFA，实际上是Bellman-Ford的队列优化
	- 为了检测负权环，我们可以对SPFA算法进行如下修改：
		1. 在每次松弛操作后，记录下每个顶点被松弛的次数。
		2. 如果某个顶点被松弛的次数超过V-1次，那么就存在一个负权环。
```C++
void SPFA(Graph& graph, int src) {
    int V = graph.V;
    vector<int> dist(V, INT_MAX);
    vector<bool> inQueue(V, false);
    queue<int> q;

    dist[src] = 0;
    q.push(src);
    inQueue[src] = true;

    while (!q.empty()) {
        int u = q.front();
        q.pop();
        inQueue[u] = false;

        // 遍历所有邻接边
        for (const Edge& edge : graph.adjList[u]) {
            int v = edge.dest;
            int weight = edge.weight;

            // 如果可以进行松弛操作，则更新距离并将顶点加入队列
            if (dist[u] != INT_MAX && dist[u] + weight < dist[v]) {
                dist[v] = dist[u] + weight;
                if (!inQueue[v]) {
                    q.push(v);
                    inQueue[v] = true;
                }
            }
        }
    }
```


# 计算机网络
- IP地址ABC类
- 以太网帧
	- 当类型字段为<=1500时，此时表示帧的长度，这是一个IEEE802.3帧
	- 当类型字段>=1500时，此时表示协议类型，这是一个以太网帧
# 编程
### 闭包

在编程语言中，闭包是一个函数，它有权访问其自身范围内的变量，也可以访问包含它的函数的变量和全局变量。闭包的主要作用是：

1. **数据封装和私有变量**：闭包可以帮助我们在函数外部隐藏或封装数据，使得这些数据只能通过特定的函数访问和修改，从而实现了类似于面向对象编程中的私有变量的效果。

2. **持久化变量**：闭包可以使得函数中的变量在函数调用结束后仍然保存其值，从而实现了变量的持久化。

3. **函数作为一等公民**：在支持高阶函数的编程语言中，闭包可以作为参数传递给其他函数，或者作为其他函数的返回值，这使得我们可以创建更加灵活和强大的抽象。

以下是一些常见的闭包的例子：

**JavaScript中的闭包**：

```javascript
function outerFunction(outerVariable) {
    return function innerFunction(innerVariable) {
        console.log('outerVariable:', outerVariable);
        console.log('innerVariable:', innerVariable);
    }
}

const newFunction = outerFunction('outside');
newFunction('inside');  // logs: outerVariable: outside, innerVariable: inside
```

在这个例子中，`innerFunction`是一个闭包，它可以访问其自身的`innerVariable`，也可以访问包含它的`outerFunction`的`outerVariable`。

**Python中的闭包**：

```python
def outer_function(x):
    def inner_function(y):
        return x + y
    return inner_function

closure = outer_function(10)
print(closure(5))  # 输出：15
```

在这个例子中，`inner_function`是一个闭包，它可以访问其自身的`y`，也可以访问包含它的`outer_function`的`x`。

## python
### lambda表达式
```python
lambda arguments: expression

sum = lambda a, b: a + b
print(sum(5, 3))  # 输出: 8


```

## Java
1. 输入输出操作
```java
import java.util.Scanner; // 导入Scanner类

public class Main {
    public static void main(String[] args) {
        Scanner scan = new Scanner(System.in); // 创建Scanner对象，用于读取标准输入

        System.out.println("请输入一个整数：");
        int num = scan.nextInt(); // 读取整数输入

        System.out.println("请输入一个字符串：");
        String str = scan.next(); // 读取字符串输入

        System.out.println("你输入的整数是：" + num);
        System.out.println("你输入的字符串是：" + str);

        scan.close(); // 关闭Scanner，释放资源
    }
}
```
2. HashMap
```java
import java.util.HashMap;

public class Main {
    public static void main(String[] args) {
        // 创建一个HashMap对象，用于存储字符串键和整数值
        HashMap<String, Integer> hashMap = new HashMap<>();

        // 添加键值对
        hashMap.put("Apple", 1);
        hashMap.put("Banana", 2);
        hashMap.put("Cherry", 3);

        // 获取值
        int value = hashMap.get("Banana");
        System.out.println("Banana的值是：" + value);

        // 检查是否包含某个键
        boolean containsKey = hashMap.containsKey("Cherry");
        System.out.println("是否包含Cherry键：" + containsKey);

        // 移除键值对
        hashMap.remove("Apple");

        // 遍历HashMap
        for (String key : hashMap.keySet()) {
            int val = hashMap.get(key);
            System.out.println("键：" + key + "，值：" + val);
        }
    }
}
```
3. ArrayList
```java
import java.util.ArrayList;

public class Main {
    public static void main(String[] args) {
        // 创建一个ArrayList对象，用于存储字符串
        ArrayList<String> arrayList = new ArrayList<>();

        // 添加元素
        arrayList.add("Apple");
        arrayList.add("Banana");
        arrayList.add("Cherry");

        // 获取元素
        String element = arrayList.get(1);
        System.out.println("索引1处的元素是：" + element);

        // 检查是否包含某个元素
        boolean contains = arrayList.contains("Cherry");
        System.out.println("是否包含Cherry：" + contains);

        // 移除元素
        arrayList.remove(0);

        // 遍历ArrayList
        for (String fruit : arrayList) {
            System.out.println("水果：" + fruit);
        }
    }
}
```
```java
 // 迭代器
 // 获取HashMap的键集合的迭代器
        Iterator<String> iterator = hashMap.keySet().iterator();

        while (iterator.hasNext()) {
            String key = iterator.next();
            int val = hashMap.get(key);
            System.out.println("键：" + key + "，值：" + val);

            // 如果需要删除元素，使用迭代器的remove方法
            if (key.equals("Banana")) {
                iterator.remove(); // 安全地删除元素
            }
        }
```

```java
public static void main(String[] args)
这个方法必须存在于一个类中，通常是程序的入口点。当Java虚拟机（JVM）启动一个应用程序时，它会寻找具有这个特定签名的 `main` 方法来开始执行。

命令行中运行时，添加参数
java MyProgram arg1 arg2 "arg3 with spaces"

for (String arg : args) {
		System.out.println(arg);
	}
	// 访问特定参数
	if (args.length > 0) {
		System.out.println("第一个参数是: " + args[0]);
	}

```
## C/C++
### lambda表达式
在C++中，lambda表达式也是一种创建匿名函数的方式。下面是一个C++的lambda表达式的例子：

```cpp
#include <iostream>
#include <vector>
#include <algorithm>

int main() {
    std::vector<int> numbers = {1, 2, 3, 4, 5};

    std::for_each(numbers.begin(), numbers.end(), [](int num) {
        std::cout << num * num << " ";
    });

    return 0;
}
```

在这个例子中，`[](int num) { std::cout << num * num << " "; }`就是一个lambda表达式。它接受一个参数`num`，并打印出`num`的平方。这个lambda表达式被传递给`std::for_each`函数，`std::for_each`函数会对`numbers`列表中的每个元素执行这个lambda表达式。

C++的lambda表达式可以捕获外部作用域中的变量，这使得它们在某些情况下非常有用。例如，你可以创建一个lambda表达式，它捕获并使用了它定义时所在作用域中的变量，如下所示：

```cpp
#include <iostream>

int main() {
    int x = 10;

    auto add_x = [x](int y) { return x + y; };

    std::cout << add_x(5) << std::endl;  // 输出: 15

    return 0;
}
```

在这个例子中，`[x](int y) { return x + y; }`是一个lambda表达式，它捕获了外部变量`x`，并在其函数体中使用了`x`。这个lambda表达式被赋值给了`add_x`，然后我们可以像调用任何其他函数一样调用`add_x`。

# 英语面试
## introduce an algorithm
```markdown
Quick Sort Algorithm

Quick Sort is a highly efficient sorting algorithm and is based on the divide-and-conquer approach. The algorithm has three main stages.

1. Divide: The algorithm picks an element as a pivot and partitions the given array around the picked pivot. 
   
   There are different versions of quick sort that pick pivot in different ways:
   - Always pick the first element as a pivot.
   - Always pick the last element as a pivot.
   - Pick a random element as a pivot.
   - Pick the median as the pivot.

2. Conquer: The array is partitioned into two sub-arrays: one with elements less than the pivot and one with elements greater than the pivot.

3. Combine: Recursively apply the above steps to the sub-arrays. The base case of the recursion is arrays of size zero or one, which are already sorted.
```
## introduce your hometown
```text
Ningbo, on the east coast of China, is known for its splendid port, which has been a major trading spot since way back in history.

This city has got a nice blend of new-school development and old-time traditions, with loads of historical spots like the Tianyi Library, Baoguo Temple.  

Ningbo is also famous for its tasty local food, like tangyuan, bamboo, juicy peaches, and yam.  

Overall, it's a pretty lively city.
```
- why do you choose xxx university?
```text
学校成就 + 自己的期望 + 印象深刻的特点 + 感想

学校成就：南京大学是中国最顶尖的学府之一，计算机科学与技术专业全国前五，享有很高的声誉。学院的教学和研究水平在国内外都有极高的评价，这对我来说是非常吸引人的。

自己的期望：我对计算机科学有着浓厚的兴趣，希望能在这里深化提升我的技术能力。相信在这里，我可以接触到最前沿的科研成果，与一流的教师和同学们一起学习和研究。

印象深刻的特点：南大的校园氛围给我留下了深刻的印象。这里的学生们积极进取，敢于挑战，这种氛围让我感到非常向往。此外，南京大学的校园环境优美，生活设施完善，这也是我选择南京大学的一个重要原因。

感想：总的来说，我认为这里能提供我所期望的学习和生活环境。我期待能在这里实现我的学术目标，同时也期待能在这里度过一段充实和愉快的大学生活。
```
- 什么是堆
	- A heap is a specialized tree-based data structure that satisfies the heap property
	- In a max-heap, the keys of parent nodes are always greater than or equal to those of the children and the highest key is in the root node
	- In a min-heap, the keys of parent nodes are less than or equal to those of the children and the lowest key is in the root node.
	- Heaps are crucial in implementing priority queues and are widely used in algorithms like Dijkstra's algorithm and Heap's algorithm.
- 如何用两个栈实现一个队列
- 对于banana这个单词，将它的每个字母打乱重组，共有多少种重组结果。（6！/12）
- 什么是冯诺依曼架构？什么是哈佛架构？
	- 冯诺依曼：指令和数据在同一个存储器
		- It is a theoretical design that forms the basis for the majority of modern computers.
		- It consists of a central processing unit (CPU), memory, and input/output mechanisms. 
		- The key feature of this architecture is the shared bus that allows data and instructions to be transferred between the CPU and memory.
		- This means at a time the bus can only transfer data or instruction, which leads to a bottleneck known as the Von Neumann bottleneck.
	- 哈佛：程序内存，数据内存分开存放
		- The Harvard architecture, in contrast to the Von Neumann architecture, separates the storage and transmission of data and instructions.
		- allows for simultaneous access to data and instructions, which can significantly increase the processing speed and efficiency of the system.
- C++和C的主要区别是什么？
	- C++ supports Obeject-Oriented Programming (OOP), Standard Template Libraray (STL), Function Overloading and Default Arguments, Exception Handling, Reference Variables,
- 用英语介绍一下KNN原理

- 机器学习，深度学习，模式识别的区别？
	- 机器学习：机器学习是人工智能的一个分支，它使计算机系统能够从数据中学习和改进，而无需进行明确的编程。机器学习的核心是开发算法，这些算法可以从数据中学习模式和规律，并使用这些学习到的知识来做出预测或决策
	- 深度学习：深度学习是机器学习的一个子集，它特别关注使用深层神经网络来模拟和学习数据中的复杂模式
	- 模式识别：模式识别与机器学习是密切相关的，模式识别中的模型学习通常会是一个机器学习任务，而机器学习通常没有考虑数据采集问题，这在模式识别系统中确实非常重要的
- 深度学习中的端到端指的是什么
	- 它直接从输入数据到最终输出结果，中间不涉及复杂的、人为设计的处理步骤或特征提取过程。这种方法强调使用一个统一的模型来处理整个任务，
	- 例子：语音识别、机器翻译、图像识别
	- 挑战：要求大量标注数据、解释性差、泛化能力
## 介绍data structure
- "Data Structures" is a fundamental concept in computer science that deals with organizing, storing, and managing data efficiently. It involves the design and implementation of methods to store and retrieve data.