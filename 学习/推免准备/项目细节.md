# 2023.03~2023.04 基于手势识别的机械臂辅助系统
## 目的
希望用户能够通过自己的便携式设备（如手机、笔记本电脑）的摄像头对远程机械臂进行控制

## 结果
没有考虑手臂的姿态，只完成了手腕的pitch（俯仰）、yaw（航向）、grip（夹握）三个轴

## 总结
在这段经历中，主要学会的是ubuntu，python等环境的配置和debug能力

这也是第一次比较多地接触使用python（python没有开设必修课）。

## 具体工作
1. 在Windows上用调用摄像头识别手部的landmarks，连接到ROS所在的主机，建立一个ROS节点用于发布消息。
2. 在Ubuntu上建立listener节点，让其自旋，接收到消息后调用callback函数；callback函数通过传送的坐标计算机械臂对应运动，通过另一个publisher节点发布消息

## 问答
- Q：ROS是什么
	Robot Operating System，机器人软件的框架。是一个中间件，提供了一些工具、库，简化用户控制机器人的代码。
	主要提供的服务有 消息传递、节点管理、包管理 等等。

- Q：两台设备之间如何通信？
	ubuntu上开启ROS Master服务器，也就是一个节点管理服务器。
	远程的主机通过roslibpy库连接到ROS Master服务器。
	底层的实现是网络套接字（sockets）
	
- Q：什么是网络套接字sockets
	应用层和传输层之间的一个**抽象接口**，允许应用程序通过网络发送和接收数据
	1. **创建套接字**：使用`socket()`函数创建一个套接字。
	2. **绑定地址**：使用`bind()`函数将套接字绑定到一个特定的网络地址和端口。
	3. **监听连接**（仅对服务器端）：使用`listen()`函数开始监听来自客户端的连接请求。
	4. **接受连接**（仅对服务器端）：使用`accept()`函数接受客户端的连接请求。
	5. **发送和接收数据**：使用`send()`和`recv()`函数（或`write()`和`read()`）在套接字上发送和接收数据。
	6. **关闭套接字**：使用`close()`函数关闭套接字，释放资源。

- Q：如何通过摄像头画面转换成坐标？
	这里调用的是mediapipe
	MediaPipe 是一个由 Google 开发的开源跨平台框架，用于构建多模态（包括视频和音频）的机器学习应用。它提供了一套丰富的预构建解决方案，如手势识别、面部识别、姿态估计等，这些解决方案可以在移动设备、桌面和服务器上运行。MediaPipe 的核心优势在于其高性能和灵活性，使得开发者可以快速构建和部署复杂的机器学习模型。

- Q：通信过程
```python
# on windows
import roslibpy

# 连接ROS_master，建立一个ros节点
client = roslibpy.Ros(host='主机号',port=端口号)
client.run()

# 创建话题，使用自定义的消息类型
# 发布者：节点名称/主题名称/消息类型
talker = roslibpy.Topic(client, '/mp_points', 'my_custom_msgs/PointArray')

# 转换消息类型，发布消息
talker.publish(roslibpy.Message(msg))
```

```python
# on ubuntu

import rospy


joints = [0, 0, 0, 0, 0, 0]  
jointState = JointState()  # 创建ROS机械臂状态话题消息变量  
pub_arm = rospy.Publisher('/joint_states', JointState, queue_size=5)  # 创建机械臂状态话题发布者，归零


def callback_func():
	# 回调函数具体内容
	# 修改joints[]的值，就是机械臂控制动作
	jointState.position = joints
	pub_arm.publish(jointState)  # ROS发布关节状态话题


def listenr():
	rospy.init_node('listenr',anonymous=True)
	# 订阅者：主题名称/消息类型/回调函数
	rospy.Subscriber('/mp_points',消息类型，回调函数)
	rospy.spin()


if __name__ == '__main__':
	listenr()
	

```

# 2023.08~2023.09 应急情况下的人员密度识别

## 目的
设想了一个场景， 在容易产生人群聚集的地方部署这块开发板，联网到监控中心，然后开发板可以在部署的地方识别人群密度。

## 结果
把程序成功迁移到了昇腾开发板上。

## 总结


## 具体工作
代码是项目组中学长已经完成的pytorch脚本，但是直接在开发板上运行时并不能调用开发板的NPU资源。
在昇腾平台上运行PyTorch业务时，需要搭建昇腾（CANN）软件开发环境
1. 环境检查：检查NPU是否在位`lspci | grep d801` 
2. 安装驱动和固件：创建驱动运行用户，安装驱动和固件，增加执行权限，通过`npu-smi info` 查看驱动加载成功
```bash
groupadd -g 1000 HwHiAiUser 
useradd -g HwHiAiUser -u 1000 -d /home/HwHiAiUser -m HwHiAiUser -s /bin/bash


chmod +x Ascend-hdk-910-npu-driver_23.0.rc1_linux-x86-64.run
chmod +x Ascend-hdk-910-npu-firmware_6.3.0.1.241.run

./Ascend-hdk-910-npu-driver_23.0.rc1_linux-x86-64.run --full --install-for-all
./Ascend-hdk-910-npu-firmware_6.3.0.1.241.run --full



```
4. 安装CANN开发套件包`./Ascend-cann-toolkit_6.3.RC1_linux-x86_64.run --install --install-for-all` 

## 问答
- Q：Atlas 200I DK A2是什么
	运行ubuntu22.04
	1个DaVinciV300 AI core（主频500MHz）
	4个TAISHANV200M处理器核（主频1.0GHz）
	半精度（FP16）：4 TFLOPS
	整数精度（INT8）：8 TOPS

- Q：代码需要进行修改吗？
	  用户仅需在脚本中添加导入训练转换库的代码即可完成PyTorch训练脚本到NPU的迁移
	```python
	import torch_npu
	import transfer_to_npu
	```
	
	或者手动将`cuda` 接口，替换为`npu` （单卡）



# 2023.03~2023.06 基于蒙特卡洛搜索的亚马逊棋下棋程序

## 目的
该项目旨在创建一个能在限定时间内做出较优决策的亚马逊棋自动下棋程序，最终将与其他下棋程序比赛
## 结果
程序在当时的排行榜上达到前10%
## 总结
## 具体工作
主要搭建了蒙特卡洛搜索的框架、ab剪枝的框架，以及评估函数。


## 问答
- Q：亚马逊棋？
	一种两人棋类。棋盘10\*10，开局双方各有4个棋子在初始位置，他们可以以国际象棋中皇后的走法进行移动。每回合一方可以移动一个棋子，并且放置一个“箭”。首先不能移动的一方判负。
	
- Q：难点在哪里？
	每一步走法数量非常庞大，平均1000步左右；第一步有2176种走法。而且限定了下棋时间，因此不可能遍历所有走法。
	
- Q：树结点的数据结构？
	父亲节点指针。从父节点走到当前节点的走法。该节点状态下，允许的下一步的所有走法。该节点的孩子指针。该结点胜利的次数，访问的次数，UCB值。
	
- Q：UCB值计算公式？
	UCB值考虑该结点的收益和该结点的被访问次数。
	![[Pasted image 20240522121323.png]]
	其中C用来控制是否更倾向于探索没有扩展过的节点。

- Q：蒙特卡洛树搜索的主要过程？
MCTS通过模拟大量的随机游戏（或称为“模拟”或“模拟”）来探索可能的决策树，并根据模拟结果来评估和选择最佳的行动。
	1. 搜索。
	2. 扩展。
	3. 模拟。
	4. 更新。
	当前节点如果还没生成过孩子，那么就扩展，然后随机走一步获得结果，反向传播。
	否则如果还能扩展孩子，就先扩展孩子，反向传播；否则找UCB值最大的点，递归调用。

- Q：ab剪枝
	先从极大极小搜索的思想开始。极大极小搜索就是站在对手的角度，多考虑了一层。
	- 假设我的一个走法可以让我得到一个很好的评估值，但是对方可以在我的走法下给我一个非常差的结果，那么我就不应该选择这个走法。
	- 假设我的一个走法可以让我得到一个较好的评估值，而对方可以基于此得到一个更加好的结果，那么我也不应该考虑走这一步。
	而ab剪枝就是考虑了这一点，a是下界，b是上界。最大值方（我）更新下界，最小值方（对方）更新上界。
```C++
//初始a为负无穷，b为正无穷
double Max_Min_Search(int depth, int now_depth, double alpha, double beta, int now_color)
{
	// 超时退出
	// 到达当前层数，评估函数评估棋盘，退出
	// 否则计算当前节点能扩展的所有子节点

	// 循环，考虑每一个子节点
		// 超时，保存当前最佳走法，退出
		// 落子，计算值，调用时depth,now_depth+1,-beta,-alpha,-now_color
		// val >= beta，剪枝
		// val > alpha，更新
}
```

- Q：评估函数
从三个维度。

领地：两方通过国王走法和皇后走法到达空格的步数和。

位置：两方通过国王走法和皇后走法到达空格的步数差值。

灵活：灵活度定义为其周围8个格子有几个空。通过国王走法到达的空格灵活度/走的步数。

## alpha-Go扩展
AlphaGo确实使用了蒙特卡洛树搜索（Monte Carlo Tree Search, MCTS）作为其核心算法之一。蒙特卡洛树搜索是一种用于决策过程的启发式搜索算法，特别适用于那些状态空间巨大且难以穷尽搜索的领域，如围棋。

在AlphaGo中，蒙特卡洛树搜索的使用方式如下：

1. **选择（Selection）**：从根节点（当前棋局状态）开始，通过一个策略函数选择一个子节点。这个策略函数会考虑每个可能的落子位置的价值，选择价值最高的节点进行扩展。

2. **扩展（Expansion）**：当选择到一个叶子节点时，如果该节点尚未完全扩展，则随机选择一个未访问的子节点进行扩展。

3. **模拟（Simulation）**：从扩展的节点开始，使用一个快速走子策略（通常是一个简单的随机策略或者基于神经网络的策略）进行模拟对局，直到对局结束。

4. **反向传播（Backpropagation）**：根据模拟对局的结果，更新从根节点到扩展节点的路径上的所有节点的统计信息，如访问次数和胜率。

AlphaGo还结合了深度学习和强化学习技术，具体包括：

- **策略网络（Policy Network）**：用于预测下一步棋的落子概率，分为快速走子策略网络和价值网络。
- **价值网络（Value Network）**：评估当前棋局状态的胜率。
- **强化学习（Reinforcement Learning）**：通过自我对弈来不断优化策略网络和价值网络。

AlphaGo的算法框架可以概括为：**通过深度学习技术训练出高水平的策略网络和价值网络，然后结合蒙特卡洛树搜索进行高效的搜索和决策**。

在AlphaGo中，快速走子网络（Fast Rollout Policy）和慢走子（或称为策略网络，Policy Network）是两种不同的策略网络，它们在蒙特卡洛树搜索（MCTS）的不同阶段发挥作用。

1. **快速走子网络（Fast Rollout Policy）**：
   - 快速走子网络是一个简单的、计算速度快的策略网络，通常基于传统的机器学习方法（如线性分类器）训练而成。
   - 它的主要作用是在蒙特卡洛树搜索的模拟（Simulation）阶段，快速地生成对局的后续走法，直到对局结束。
   - 由于其计算速度快，可以在短时间内进行大量的模拟对局，从而为MCTS提供大量的统计数据。
   - 快速走子网络虽然不如慢走子网络精确，但它的速度优势使得它非常适合在模拟阶段使用。

2. **慢走子（Policy Network）**：
   - 慢走子网络是一个深度神经网络，通过监督学习和强化学习训练而成，能够预测围棋专家的走子概率。
   - 它在蒙特卡洛树搜索的选择（Selection）和扩展（Expansion）阶段使用，用于评估每个可能的落子位置的价值。
   - 慢走子网络的输出是一个概率分布，表示在当前棋局状态下每个可能落子位置的优先级。
   - 在选择阶段，MCTS会根据慢走子网络的输出选择最有希望的子节点进行探索。
   - 在扩展阶段，慢走子网络也会用于选择新的子节点进行扩展。

**总结来说，快速走子网络在MCTS的模拟阶段提供快速的走子策略，而慢走子网络在选择和扩展阶段提供更精确的走子评估。**两者结合使用，使得AlphaGo能够在保持搜索效率的同时，做出高质量的决策。

# 2024.03~05 SNL语言编译器

## 目的
制作一个SNL语言的编译器，将源代码编译为可运行程序。
完成了词法分析、语法分析、语义分析、目标代码生成，并且最终的目标代码可以运行。
## 具体工作
我完成了语法分析、目标代码生成的部分。
- 语法分析：采用递归下降法进行语法分析。建立语法树节点，以及各种需要用到的枚举等数据结构；扫描Token形式的源程序，最终形成语法树结构，返回语法树根节点。
- 目标代码生成：建立TM寄存器枚举结构；将语法树以及对应的语义信息转换为TM汇编代码。

## 问答
-  词法分析的一些细节
	- 读入源程序，解析为token序列`(line,type,value)` 
	- LexicalType：特殊符号、保留字、标识符/整数/字符串
	- 用接口定义类型的公有属性
- 语法分析
	- 语法树节点类型（标志结点、具体节点）、声明类型（数组、字符...）、语句类型（if、while...）、表达式类型（运算符、常数、变量）、变量类型（标识符、数组、记录）、参数类型（传值、传地址）
	- 具体节点 有 具体内容
		- 声明结点：声明类型（字符串、标识符、过程）、属性
		- 语句节点：语句类型
		- 表达式结点：表达式类型、具体属性
- 语义分析
	- 基本类型（整数、字符、数组、记录、布尔等）、标识符类型（类型、变量、过程）、类型的内部表示（大小、基础类型、每个类型所包含的独有属性）、基础类型的表示、变量的访问类型、标识符的内部表示（种类、类型的内部表示、变量/过程标识符的属性）、语义分析表项
- ![[Pasted image 20240602142707.png]]
- 介绍一下SNL语言
	- SNL(Small Nested Language) ，自行定义的教学模型语言，类Pascal的”高级”程序设计语言。
	- 数据类型：整型、字符型，数组、记录。
	- 允许递归调用。
	- 给出了该语言的上下文无关文法
- 介绍一下TypeScript语言
	- 是 JavaScript 的超集，主要增加了静态类型检查和面向对象编程的特性。TypeScript 代码可以编译成纯 JavaScript，从而在任何支持 JavaScript 的环境中运行。
	- 主要特点包括：静态类型检查、面向对象编程、函数是一等公民
	- TypeScript主要用于前端开发。依赖JavaScript的垃圾回收机制自动管理内存。编译后可以在Node.js环境执行
- typescript和javascript区别
	- js是解释型的语言，ts需要先编译成js
	- ts会在编译的时候进行静态类型检查
	- TypeScript 提供了更完善的类和接口支持
- typescript如何管理动态类型和静态类型相结合？
	- 静态类型检查：允许给变量和返回值**添加类型注解**，提供接口和别名来定义复杂的类型，编译器支持上下文类型推断。
	- 动态类型支持：提供any类型；类型断言（someVal as string）
- 函数是一等公民怎么理解？
	- 指的是函数在语言中有和其他基本类型相同的地位和待遇，具体地说可以：
		- 函数赋值给变量 
		- 函数作为参数传递
		- 作为返回值
		- 存储在数据结构中
	- python、ruby、lisp等也支持函数一等公民
## C++编译过程
1. 预处理
	- 头文件、宏替换和条件编译
2. 词法分析
3. 语法分析
4. 生成中间代码或汇编代码
5. 链接

# 2024.02~ 视频隐私保护
## 目的
我现在设想的是，部署在监控终端上，直接将内存中的视频流识别出人物面部并且加密，然后将加密数据存储到硬盘中。也就是未加密的信息不会存储到硬盘中，只会在内存中存在一段时间，保证安全性。

## 具体工作
- 假期的时候尝试复现了一篇论文：用YOLO识别出人的面部，把识别结果padding为16/32/64的倍数，然后对每个通道单独处理
	- 首先16/32/64分块，每个块z字重排，顺时针旋转，重新排序，和密码进行异或；保存加密过程中的参数便于恢复
	- 最后有十多个指标用于评估加密是否足够严格。比如视觉（肉眼）分析、直方图分析（分布均匀）、信息熵分析、像素相关性分析（多个方向）、差分攻击分析、SSIM结构相似性分析、边缘检测分析、键空间分析、键敏感性分析、噪声攻击分析，与原文的数值基本一致。
- 但是上述方法丧失了直观性，肉眼上看，丢失了语义信息，而且需要把解密的key保存到本地，不够安全。
- 因此重新考虑，[[视频隐私保护]]
## 问答
- Q：密码是怎么生成的？
	- 混沌逻辑映射，当lamda取3.57~4时，生成的序列就是混沌的
- ![[Pasted image 20240522202222.png]]
- Q：信息熵分析
	- -plogp
	- ![[Pasted image 20240523084807.png]]

# 2024.03-05 B+树

# 2024.07 莎士比亚GPT

## Let's build GPT from scratch, in code, spelled out
- [Andrej Karpathy《从零开始搭建GPT|Let's build GPT from scratch, in code, spelled out》中英字_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1v4421c7fr/)
- https://www.youtube.com/watch?v=kCc8FmEb1nY
- Google colab for the video: [https://colab.research.google.com/dri...](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing) 
- GitHub repo for the video: [https://github.com/karpathy/ng-video-...](https://github.com/karpathy/ng-video-lecture) 
- 数据集：莎士比亚集，一百万字符
- 优化过程：
	1. 
	2. 最简单的二元模型
	3. 单头注意力：token之间交流 2.8
	4. 多头注意力：并行运行多个单头注意力，减少head大小，增加头数量
	5. 多头注意力+MLP：每个token可以在MLP下进行更多的思考
	6. 多层块：一个块是`多头注意力+MLP` 
	7. 残差连接：在多头注意力和MLP中加入跳跃连接，使更深的网络也可以得到训练 val_loss = 2.08，并且开始过拟合
	8. LayerNorm：与attention论文不同，在self_attention和MLP前使用`Add&Norm` ，使每个token标准化 val_loss = 2.06
	9. dropout以及更深的层：val_loss = 1.48，train_loss = 1.07，可以产生比较像莎士比亚的输出了。

## embedding_size和head_size的关系



## 注意力机制为什么除根号dk

在注意力机制中，除以根号dk（即键向量维度 𝑑𝑘​ 的平方根）是为了缩放注意力分数，这是一个重要的步骤，原因如下：

1. **数值稳定性**：当键向量维度 𝑑𝑘 较大时，查询向量和键向量之间的点积可能会变得非常大。这些大的数值在通过softmax函数时，可能会导致梯度消失或梯度爆炸的问题，因为softmax函数对于输入的极值非常敏感。通过除以根号dk，可以有效地将注意力分数缩放到一个更合理的范围内，从而提高数值稳定性。
    
2. **注意力分布的平滑性**：softmax函数在输入值较大时，会输出一个非常尖锐的概率分布，即少数几个值接近1，而其他值接近0。这种尖锐的分布可能会导致模型过于关注输入序列中的某一个或几个元素，而忽略了其他可能也很重要的元素。通过缩放注意力分数，可以使注意力分布更加平滑，从而使得模型能够更均匀地关注输入序列中的多个元素。
## word->index->embedding
以下是一个如何在PyTorch中将字符转换为嵌入向量的示例：

1. **定义字符到索引的映射**：首先，你需要为每个字符分配一个唯一的整数索引。
    
2. **创建嵌入层**：然后，你创建一个嵌入层，它将这些索引映射到嵌入向量。
    
3. **将字符转换为索引**：将输入字符串中的每个字符转换为对应的索引。
    
4. **通过嵌入层获取嵌入向量**：使用嵌入层将这些索引转换为嵌入向量。
    
5. **训练嵌入层**：在训练过程中，嵌入层的权重（即嵌入向量）会根据损失函数进行调整，以更好地适应你的任务。
## Bigram

在bigram模型中，假设当前词的出现仅依赖于它前面的一个词，而不是整个句子或更长的上下文。数学上，这种依赖关系可以表示为条件概率：

P(w\_n | w\_n-1)

其中，w\_n 是当前词，w\_n-1 是前一个词。这个条件概率表示在给定前一个词 w\_n-1 的情况下，当前词 w\_n 出现的概率。

为了构建一个bigram模型，通常需要一个大型文本语料库，从中统计每个可能的bigram出现的频率。然后，这些频率可以转换为概率，用于预测或生成文本。例如，如果语料库中“I am”出现的次数很多，那么模型可能会给“am”在“I”之后出现的概率分配一个较高的值。

尽管bigram模型非常简单，但它在许多实际应用中仍然有效，尤其是在计算资源有限或需要快速处理的情况下。然而，它也有局限性，因为它没有考虑更长的上下文信息，这可能导致在处理复杂语言结构时出现错误。为了克服这些限制，可以使用更复杂的模型，如trigram模型（考虑前两个词）、n-gram模型（考虑前n-1个词）或基于神经网络的模型（如LSTM或Transformer），这些模型可以捕捉更长的依赖关系。


这段代码是一个完整的GPT（Generative Pre-trained Transformer）模型的实现，用于生成文本。下面是对每个部分的概述：

1. **数据准备**：
   - 下载并读取莎士比亚的小型文本数据集。
   - 计算数据集的长度并打印前1000个字符。
   - 提取所有唯一的字符并创建字符到整数的映射（编码器）和整数到字符的映射（解码器）。

2. **数据编码**：
   - 将整个文本数据集编码为整数张量，并转换为PyTorch张量。
   - 将数据集分为训练集和验证集（90%训练集，10%验证集）。

3. **数据批处理**：
   - 定义一个函数`get_batch`来生成小批量的输入和目标数据。

4. **模型定义**：
   - 定义一个简单的Bigram语言模型，该模型使用嵌入表来预测下一个字符。
   - 定义生成函数，用于生成新的文本序列。

5. **模型训练**：
   - 创建一个优化器（AdamW）并进行模型训练。
   - 在每个迭代步骤中，计算损失并进行反向传播和参数更新。

6. **自注意力机制**：
   - 通过矩阵乘法演示自注意力的加权聚合机制。
   - 定义自注意力头（Head）和多头注意力（MultiHeadAttention）。

7. **层归一化**：
   - 定义层归一化（LayerNorm）类，用于归一化输入数据。

8. **完整模型**：
   - 定义完整的Bigram语言模型，包括嵌入层、位置嵌入层、多个Transformer块、最终的层归一化和语言模型头。
   - 进行模型训练和生成文本。

9. **评估和生成**：
   - 定期评估训练和验证集的损失。
   - 生成新的文本序列并打印出来。

整体来看，这段代码实现了一个完整的GPT模型，包括数据准备、模型定义、训练和生成文本的流程。通过这个模型，可以生成连贯的莎士比亚风格的文本。

# 2024.07 智能递送助手

阿里Paraformer实时流式语音识别
文心一言ernie-bot做决策和函数调用
通义千问Qwen-VL进行物体识别返回坐标

# 2424.07 P概率掩码卷积

### Dropout在卷积层中的应用

在卷积神经网络（CNN）中，Dropout同样可以用于防止过拟合。虽然Dropout最初是为全连接层设计的，但它也可以应用于卷积层。在卷积层中应用Dropout时，通常有两种方式：

1. **标准Dropout**：在卷积层之后应用Dropout。具体做法是，在**卷积层输出的特征图**上随机选择一部分像素，并将其值设置为0。这种方式与在全连接层中应用Dropout类似。
    
2. **空间Dropout（Spatial Dropout）**：这是一种专门为卷积层设计的Dropout变体。在空间Dropout中，不是随机丢弃单个像素，而是随机丢弃整个特征图（即整个通道）。这样做的好处是保留了特征图的空间结构，同时减少了通道之间的依赖关系。

### 《块稀疏CNN：迈向快速且内存高效的卷积神经网络框架》
引入稀疏矩阵来随机化卷积核，减少存储空间要求和时间复杂性，但通常不会提高模型的准确性。

1.块稀疏化策略：将卷积层的权重矩阵划分为固定大小的块。对这些块进行稀疏化处理，即只保留重要的块，而将不重要的块置为零。
2.计算优化：设计了一种高效的稀疏卷积算法，该算法能够跳过零块的计算，从而减少不必要的计算操作。结合硬件优化，如利用现代GPU的并行计算能力，进一步提高计算效率。
### 传统的稀疏性方法

**稀疏性**在机器学习中通常指的是在一个矩阵中大部分元素为零的情况。在传统的稀疏性方法中，以下两种是最常见的方法：

1. **随机稀疏性**：
   - 在随机稀疏性方法中，会随机将权重矩阵中的一部分个体元素设为零。通过这种方式可以减少非零元素的数量，从而减小计算量和内存使用。
   - 然而，这种方法会带来模型训练不稳定和性能下降的问题，因为权重矩阵中的个体元素被无序地设为零，可能会破坏权重矩阵的重要结构和信息。
   - 
1. **结构化稀疏性**：
   - 在结构化稀疏性方法中，会按**一定规则将整个行或列设为零**。这比随机稀疏性更利于硬件优化，轻易不会破坏权重矩阵的结构，虽然相比随机稀疏性产生的零元素更少。
   - 但即便是结构化稀疏性，在保存一定数量的非零权重必要的情况下，仍会带来一定的精度损失。

### 块稀疏性方法
**块稀疏性**是对稀疏化策略的一种改进，它的核心思想是将权重矩阵分割成若干个较小的子块，每个子块进行独立的稀疏化处理。具体步骤如下：
1. **分块**：
   - 将权重矩阵划分成若干个大小相同的子块。例如，一个大的权重矩阵可能会被分割成多个 \(4 \times 4\) 或更大/更小的矩形子块。
2. **块内稀疏化**：
   - 每个子块内部采用稀疏性策略，使得每个块中的某些元素被设为零，但每个子块仍会保留一定数量的非零元素。
   - 由于是对子块进行稀疏化处理，块与块之间的结构性依旧保留，大大降低了信息丢失和结构破坏的风险。

### 《交错结构化稀疏卷积神经网络》

IGCV2型

将两个结构化稀疏内核扩展到更结构化的稀疏内核的乘积

引入互补和平衡条件

模型大小、计算复杂度、分类性能

