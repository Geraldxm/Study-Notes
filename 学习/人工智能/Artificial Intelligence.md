# NLP - 自然语言处理


#### Byte Pair Encoding (BPE) - 字节对编码

- 提出背景：
	- 对中文和英文来说，字符级别的嵌入都有一定的困难：英文中有意义的文本会比较长(输入序列对应的时间步较多)，训练慢，遗忘严重；中文有几万个字(分类标签较多)，训练慢。
	- 词嵌入的困难就更明显了，当前主要语言的词汇表都是十万级别大小，导致模型训练非常耗时。
		- 控制词汇表规模，大家做了很多尝试:去除停用词；对英文文本做tokenization；将“不重要的”字、词替换为统一的符号；将数字替换为统一的符号；(中文中)将英文字符替换为统一的符号；字嵌入
- 字节对编码，BPE
	- 用一个新代号表示数据中最常见的bigram(可以是字节对、字符对、词语对等等)，不断迭代
## OOV问题(词汇表外)

### 产生原因
真实使用场景可能会输入训练文本中不存在的词
### 处理方式
- 将所有未知单词都替换为一个特殊的OOV标记，然后将其当做一个单独的单词来处理。
	- 但是这种方法可能会导致模型的性能下降，因为OOV标记无法提供关于未知单词的任何语义信息。

## GPT-2

- Languager Models are Unsupervised Multitask Learners
- 在之前的机器学习系统中，主要方法是收集一组训练示例数据集，展示其正确行为，训练系统模仿这些行为。
	- 有助于创建专家系统，但是在输入多样性的表现上不稳定
- GPT-2
### 

# ML - 机器学习

## LoRA

### 直觉理解
**lora是大模型的低秩适配器，或者就简单的理解为适配器**，在图像生成中可以将lora理解为某种图像风格（比如SD社区中的各种漂亮妹子的lora，可插拔式应用，甚至组合式应用实现风格的融合）的适配器，在NLP中可以将其理解为某个任务的适配器（比如最近各种开源chatgpt复现中使用的lora技术，不过限于文本领域的特性，目前组合式应用似乎还不多）。
### 原理
motivation：low intrinsic dimension，模型是过参数化的，它们有更小的内在维度，模型主要依赖于这个低的内在维度（low intrinsic dimension）去做任务适配。假设**模型在适配任务时参数的改变量是低秩的**，由此引出低秩自适应方法lora，**通过低秩分解来模拟参数的改变量**，从而以极小的参数量来实现大模型的间接训练。

### 做法
- 在原模型旁边增加一个旁路，**通过低秩分解（先降维再升维）来模拟参数的更新量**；
- 训练时，原模型固定，只训练降维矩阵A和升维矩阵B；
- 推理时，可将BA加到原参数上，不引入额外的推理延迟；
- 初始化，A采用高斯分布初始化，B初始化为全0，保证训练开始时旁路为0矩阵；
- 可插拔式的切换任务，当前任务W0+B1A1，将lora部分换成B2A2，即可实现任务切换；
- 秩的选取：对于一般的任务，rank=1,2,4,8足矣，而对于一些领域差距比较大的任务可能需要更大的rank。

## 卷积核

$$ \text{output\_width} = \left\lfloor \frac{\text{input\_width} + 2 \times \text{padding} - \text{dilation} \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1 \right\rfloor $$ 
$$ \text{output\_height} = \left\lfloor \frac{\text{input\_height} + 2 \times \text{padding} - \text{dilation} \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1 \right\rfloor $$ 

## nn modules
在PyTorch中，`nn` 模块提供了构建神经网络所需的各种组件和工具。以下是一些常用的 `nn` 模块组件：

1. **层（Layers）**：
   - `nn.Linear`：全连接层（线性层）。
   - `nn.Conv2d`：二维卷积层。
   - `nn.Conv1d`：一维卷积层。
   - `nn.Conv3d`：三维卷积层。
   - `nn.MaxPool2d`：二维最大池化层。
	   - `nn.AdaptiveMaxPool2d` 
   - `nn.AvgPool2d`：二维平均池化层。
	   - `nn.AdaptiveAvgPool2d` 
   - `nn.BatchNorm2d`：二维批量归一化层。
	   - 加速收敛、提高模型稳定性、正则化
   - `nn.Dropout`：随机丢弃层。

2. **激活函数（Activation Functions）**：
   - `nn.ReLU`：修正线性单元激活函数。
	   - inplace: 用于原地操作，直接修改输入张量节省内存
   - `nn.Sigmoid`：Sigmoid激活函数。
   - `nn.Tanh`：双曲正切激活函数。
   - `nn.Softmax`：Softmax激活函数。

3. **损失函数（Loss Functions）**：
   - `nn.MSELoss`：均方误差损失函数。
   - `nn.CrossEntropyLoss`：交叉熵损失函数。
   - `nn.NLLLoss`：负对数似然损失函数。
   - `nn.BCELoss`：二元交叉熵损失函数。

4. **优化器（Optimizers）**：
   - `torch.optim.SGD`：随机梯度下降优化器。
   - `torch.optim.Adam`：Adam优化器。
   - `torch.optim.RMSprop`：RMSprop优化器。

5. **数据加载和预处理（Data Loading and Preprocessing）**：
   - `torch.utils.data.DataLoader`：数据加载器。
   - `torchvision.transforms`：图像预处理和数据增强工具。

6. **模型容器（Model Containers）**：
   - `nn.Sequential`：顺序容器，用于按顺序堆叠多个层。
   - `nn.ModuleList`：模块列表，用于存储多个层或模块。
   - `nn.ModuleDict`：模块字典，用于存储多个层或模块。

7. **工具函数（Utility Functions）**：
   - `nn.functional`：包含各种激活函数、损失函数和其他功能的函数接口。
   - `nn.init`：用于初始化模型参数的工具函数。

8. 神经网络层
- `nn.TransformerEncoderLayer` 
- `nn.RNN` 
- `nn.LSTM` 


这些组件和工具使得在PyTorch中构建、训练和评估神经网络变得非常方便和灵活。通过组合这些组件，您可以创建各种复杂的神经网络架构，以适应不同的任务和数据类型。
## LSTM

长短期记忆（Long Short-Term Memory, LSTM）是一种特殊的递归神经网络（Recurrent Neural Network, RNN）架构，它被设计用来解决传统RNN在处理长序列数据时遇到的梯度消失和梯度爆炸问题。LSTM由Sepp Hochreiter和Jürgen Schmidhuber在1997年提出，它在许多序列预测任务中表现出色，尤其是在需要捕捉长距离依赖关系的任务中。

LSTM的核心思想是通过引入一种称为“记忆单元”（memory cell）的结构来维护和控制信息的流动。记忆单元允许网络选择性地记住或忘记信息，这使得LSTM能够学习长期依赖关系。LSTM单元由几个关键部分组成：

1. **输入门（Input Gate）**：决定哪些新的信息应该被加入到记忆单元中。

2. **遗忘门（Forget Gate）**：决定哪些信息应该从记忆单元中丢弃或保留。

3. **输出门（Output Gate）**：基于记忆单元的内容，决定哪些信息应该输出。

4. **记忆单元（Cell State）**：LSTM的核心，负责存储长期信息。

这些门和记忆单元通过一系列的线性和非线性操作（如sigmoid激活函数和tanh激活函数）来控制信息的流动。具体来说，输入门、遗忘门和输出门使用sigmoid函数来产生0到1之间的值，这些值决定了信息通过的程度。记忆单元则使用tanh函数来产生-1到1之间的值，这些值代表了记忆单元中的信息。

LSTM的工作流程如下：

- **遗忘门**：根据当前输入和前一时刻的隐藏状态，计算一个遗忘向量，决定哪些信息从记忆单元中丢弃。
- **输入门**：根据当前输入和前一时刻的隐藏状态，计算一个输入向量，决定哪些新的信息应该被加入到记忆单元中。
- **记忆单元更新**：使用遗忘门和输入门的输出，更新记忆单元的状态。
- **输出门**：根据当前输入和前一时刻的隐藏状态，计算一个输出向量，决定记忆单元的哪些信息应该输出。
- **隐藏状态**：使用输出门的输出和更新后的记忆单元，计算当前时刻的隐藏状态，这个隐藏状态将作为下一时刻的输入之一。

通过这种机制，LSTM能够有效地学习到序列数据中的长期依赖关系，从而在诸如语音识别、自然语言处理、时间序列预测等领域取得了显著的成功。

## 超参数
超参数确实可以由计算机自动优化，这一过程通常被称为超参数优化（Hyperparameter Optimization）或超参数调优（Hyperparameter Tuning）。随着机器学习领域的发展，已经开发出了多种自动化的方法来寻找最优的超参数组合，这些方法包括但不限于：

1. **网格搜索（Grid Search）**：系统地在预定义的超参数空间中搜索所有可能的组合，以找到最佳的参数组合。

2. **随机搜索（Random Search）**：在超参数空间中随机选择组合进行评估，这种方法在某些情况下比网格搜索更有效，尤其是当某些超参数对模型性能影响不大时。

3. **贝叶斯优化（Bayesian Optimization）**：使用概率模型来预测哪些超参数组合可能表现更好，并根据这些预测来选择下一个要评估的点。

4. **遗传算法（Genetic Algorithms）**：受自然选择过程启发，通过模拟进化过程来优化超参数。

5. **梯度下降优化（Gradient-based Optimization）**：对于某些超参数，如果可以计算其对模型性能的梯度，则可以使用梯度下降方法进行优化。

6. **基于模型的优化（Model-based Optimization）**：使用机器学习模型来预测超参数的性能，并据此进行优化。

7. **自动机器学习（AutoML）**：使用自动化工具和框架来探索和优化超参数，这些工具通常结合了多种优化技术。

尽管有这些自动化的方法，超参数优化仍然是一个计算密集型的过程，因为它通常需要在不同的超参数组合上多次训练和评估模型。此外，自动化的超参数优化也可能需要领域知识来定义合适的搜索空间和评估标准。因此，虽然计算机可以自动优化超参数，但这个过程仍然需要人工的参与和指导。

## train, validation, test

### 为什么不能仅仅划分训练集和测试集，并且在测试集上选择最佳模型或调整超参数？

仅仅划分训练集和测试集，并在测试集上选择最佳模型或调整超参数的做法存在一些潜在的问题，主要涉及到模型的泛化能力和评估的公正性。以下是具体的原因：

1. **过拟合风险**：
   - 如果在测试集上直接选择模型或调整超参数，模型可能会**过度适应测试集的特定特征，导致过拟合。** 过拟合意味着模型在测试集上表现良好，但在新的、未见过的数据上表现不佳。

2. **评估偏差**：
   - 测试集的目的是提供一个无偏的评估，反映模型在实际应用中的表现。如果在测试集上进行模型选择或调参，测试集就不再是一个无偏的评估工具，因为它已经被用于指导模型的优化过程。

3. **泛化能力受损**：
   - 模型的泛化能力是指模型在新的数据上的表现。如果在测试集上进行模型选择或调参，模型的泛化能力可能会受到损害，因为它已经“看到”了测试集的数据特征。

4. **验证集的作用**：
   - 验证集的引入是为了在模型训练过程中提供一个独立的评估标准。通过在验证集上选择模型和调整超参数，我们可以确保测试集的独立性和无偏性，从而更准确地评估模型的泛化能力。

总结来说，使用验证集可以帮助我们在模型训练过程中监控和调整模型的性能，而测试集则用于最终的无偏评估。这种划分确保了模型的选择和调参过程不会影响测试集的独立性，从而更准确地评估模型的实际应用表现。


## 传统的图像分类神经网络

一个传统的图像分类神经网络通常由以下几个主要部分组成：

1. **输入层（Input Layer）**：输入层接收原始图像数据，通常是一个三维数组（高度、宽度、通道），其中通道通常代表颜色通道（例如，RGB图像有三个通道）。

2. **卷积层（Convolutional Layers）**：卷积层是图像分类网络的核心部分，它们使用一组可学习的滤波器（或称为卷积核）来对输入图像进行卷积操作，以提取图像的局部特征。每个卷积层可以包含多个卷积核，每个卷积核生成一个特征图（feature map）。

3. **激活函数（Activation Function）**：在卷积层之后，通常会应用一个非线性激活函数，如ReLU（Rectified Linear Unit），以增加网络的非线性表达能力。

4. **池化层（Pooling Layers）**：池化层用于降低特征图的空间维度（高度和宽度），减少计算量，并增强特征的平移不变性。常见的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。

5. **全连接层（Fully Connected Layers）**：在经过多个卷积和池化层之后，网络的输出会被展平（flatten）成一个一维向量，然后送入一个或多个全连接层。全连接层的作用是将之前提取的局部特征组合起来，以进行最终的分类决策。

6. **输出层（Output Layer）**：输出层通常是一个带有softmax激活函数的全连接层，用于输出每个类别的概率分布。对于一个有N个类别的分类问题，输出层会有N个神经元。

7. **损失函数（Loss Function）**：在训练过程中，损失函数用于衡量模型预测的输出与真实标签之间的差异。常见的损失函数包括交叉熵损失（Cross-Entropy Loss）。

8. **优化器（Optimizer）**：优化器用于更新网络的权重和偏置，以最小化损失函数。常见的优化算法包括SGD（Stochastic Gradient Descent）、Adam（Adaptive Moment Estimation）等。

一个典型的例子是LeNet-5，它是最早的卷积神经网络之一，用于手写数字识别。另一个著名的例子是AlexNet，它在2012年的ImageNet竞赛中取得了突破性的成绩，展示了深度卷积神经网络在图像分类任务中的强大能力。随后，VGG、GoogLeNet和ResNet等网络架构也被广泛应用于图像分类任务。

## Res-Net 如何解决梯度消失、梯度爆炸

ResNet，即残差网络，是一种深度学习模型，它通过引入“残差块”（Residual Block）来解决深度神经网络中的梯度爆炸和梯度消失问题。

**梯度消失和梯度爆炸问题**：在深度神经网络中，当网络层数增加时，梯度在反向传播过程中可能会出现急剧衰减或急剧增大的现象，这就是梯度消失和梯度爆炸问题。这两个问题会严重影响网络的学习效果。

**残差块**：ResNet的关键创新是引入了残差块。在每个残差块中，输入不仅被传递到后面的层，还会被直接添加到后面的层的输出上。这种“跳跃连接”（Skip Connection）或“短路连接”（Shortcut Connection）使得网络可以学习输入和输出之间的残差映射，从而避免了梯度消失和梯度爆炸问题。

**解决梯度消失和梯度爆炸**：在ResNet中，由于存在跳跃连接，梯度可以直接从后面的层传播到前面的层，避免了在深层网络中梯度消失的问题。同时，由于**每个残差块学习的是残差映射，即输入和输出的差值**，这使得网络的学习目标更加明确，也有助于防止梯度爆炸。

总的来说，ResNet通过引入残差块和跳跃连接，有效地解决了深度神经网络中的梯度消失和梯度爆炸问题，使得我们可以训练更深的神经网络。
## 损失函数
### 交叉熵损失
- nn.BCEloss：二分类
	- LOSS=-(ylog(p(x)+(1-y)log(1-p(x))
- nn.CrossEntropyLoss：多分类，**softmax + log + NLLloss = crossEntropyLoss**。
## 正则化，标准化区别，以及一些正则化和标准化的方法

### 正则化 Regularization
- 正则化是防止模型过拟合的一种技术，通过向损失函数中添加惩罚项，限制模型的复杂度，避免过拟合。
1. **L1 正则化**：在损失函数中添加权重的绝对值之和，即 𝜆∑∣𝑤𝑖∣，其中 𝜆 是正则化强度，𝑤𝑖​ 是模型的权重。L1 正则化倾向于产生稀疏权重，即许多权重为零。
2. **L2 正则化**：在损失函数中添加权重的平方和，即 𝜆∑𝑤𝑖^2​。L2 正则化倾向于使权重值较小，但不会产生稀疏权重。
3. **Dropout**：在训练过程中随机丢弃一部分神经元，从而防止神经元之间过度协同适应。
4. **Early Stopping**：在验证集上的性能不再提升时提前停止训练，从而避免过拟合。
### 标准化 Normalization
- 标准化是一种数据预处理技术，用于将数据转换为具有一致的尺度，从而提高模型的训练效率和稳定性。标准化通常应用于输入数据，但也可以应用于网络的中间层。
1. **Min-Max 标准化**：将数据缩放到一个特定的范围，通常是 [0, 1] 或 [-1, 1]。公式为 𝑥′=𝑥−min⁡(𝑥)max⁡(𝑥)−min⁡(𝑥)x′=max(x)−min(x)x−min(x)​。
2. **Z-score 标准化**：将数据转换为均值为 0，标准差为 1 的分布。公式为 𝑥′=𝑥−𝜇𝜎x′=σx−μ​，其中 𝜇μ 是均值，𝜎σ 是标准差。
3. **Batch Norm**：在深度学习中，Batch Norm 通过对每个 mini-batch 的数据进行归一化处理，使得网络的每一层的输入分布保持稳定。
4. **Layer Norm**：对每个样本的所有特征进行归一化，而不是对每个特征维度进行归一化，适用于小批量数据和序列数据。
#### 对输入数据进行标准化
- 数据预处理技术，目的是将输入数据的分布调整到一个一致的尺度，从而提高模型的训练效率和稳定性。常见的输入数据标准化方法包括 Min-Max 标准化和 Z-score 标准化。
- 
- **提高训练效率**：标准化后的数据分布更加一致，有助于加速模型的收敛速度。 
- **减少数值稳定性问题**：标准化可以减少由于数据尺度差异导致的数值稳定性问题，如梯度消失或梯度爆炸。
- **提高模型性能**：标准化有助于模型更好地学习数据的特征，从而提高模型的性能。
#### 对网络权重进行标准化
- 对网络权重进行标准化是指在神经网络的训练过程中，对每一层的权重进行调整，使其满足某种分布要求。这一技术也被称为“权重归一化”（Weight Normalization）。

- **防止过拟合**：通过限制权重的分布，可以减少模型的复杂度，从而降低过拟合的风险。
- **提高模型的泛化能力**：权重标准化有助于模型在未见过的数据上表现更好。
- **稳定训练过程**：权重标准化可以减少权重的大小，从而减少梯度更新的方差，使训练过程更加稳定。
### dropout
- Dropout 是一种常用的正则化技术，用于减少神经网络的过拟合风险。它在训练过程和推理过程中的行为有所不同。

在训练过程中，Dropout 通过随机丢弃（即设置为零）网络中的一部分神经元来实现正则化，防止网络过于依赖某些特定的神经元，从而提高模型的泛化能力。具体步骤如下：

1. **随机丢弃神经元**：在每次前向传播时，Dropout 以概率 𝑝（称为丢弃率）随机选择网络中的一部分神经元，并将这些神经元的输出设置为零。这意味着在每次迭代中，网络的结构都会有所不同。
    
2. **缩放剩余神经元的输出**：为了保持网络的期望输出不变，Dropout 会对剩余的神经元输出进行缩放。具体来说，如果一个神经元没有被丢弃，它的输出会乘以 1/(1-p)。

在推理过程中，Dropout 的行为有所不同，以确保模型的输出是确定的，并且与训练时的期望输出一致。具体步骤如下：

1. **禁用 Dropout**：在推理过程中，Dropout 被完全禁用，即所有神经元都参与计算。
2. **模型效果优化**：由于推理过程中没有神经元被丢弃，输出层计算会基于所有神经元的综合信息，从而提高预测的稳定性和准确性。

## backbone、head、bottleneck、Embedding、Warm up、end to end
- backbone：
	- 主干网络大多时候指的是提取特征的网络，**其作用就是提取图片中的特征，供后面的网络使用**
	- 经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的
	- 直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。
- neck:
	- 是放在backbone和head之间的，是为了**更好的利用backbone提取的特征**，**对backbone提取的特征进行特征融合**，**输出具有相同宽度的特征图，提供head使用。**
- head
	- head是获取网络输出内容的网络，**利用之前提取的特征，head利用这些特征，做出预测**
- Embedding:
	- 深度学习方法都是利用使用线性和非线性转换对复杂的数据进行自动特征抽取，并将特征表示为“向量”（vector），这一过程一般也称为“嵌入”（embedding）
- Warm up
	Warm up指的是用一个小的学习率先训练几个epoch，这是因为网络的参数是随机初始化的，一开始就采用较大的学习率容易数值不稳定。

- end to end
	在论文中经常能遇到end to end这样的描述，那么到底什么是端到端呢？其实就是给了一个输入，我们就给出一个输出，不管其中的过程多么复杂，但只要给了一个输入，机会对应一个输出。比如分类问题，你输入了一张图片，肯呢个网络有特征提取，全链接分类，概率计算什么的，但是跳出算法问题，单从结果来看，就是给了一张输入，输出了一个预测结果。End-To-End的方案，即输入一张图，输出最终想要的结果，算法细节和学习过程全部丢给了神经网络。
## 知名的数据库和期刊、会议
- 数据库：
1. **IEEE Xplore Digital Library**
2. **ACM Digital Library**
- 期刊和会议：
1. **Journal of Artificial Intelligence Research (JAIR)**：这是一份专注于人工智能研究的学术期刊，发表了许多在人工智能领域具有影响力的研究成果。
2. **Artificial Intelligence (AI)**：这是一份全面涵盖人工智能领域的学术期刊，包括机器学习、计算机视觉、自然语言处理等多个子领域。
3. **IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)**：这是一份由IEEE出版的期刊，主要关注模式识别、计算机视觉和图像处理等领域的研究。
4. **Neural Information Processing Systems (NeurIPS)**：这是一场在人工智能和机器学习领域具有极高影响力的年度会议，每年都会吸引全球的研究人员提交他们的最新研究成果。
5. **International Conference on Learning Representations (ICLR)**：这是一场专注于表示学习和深度学习的国际会议，每年都会展示这个领域的最新进展。
6. **Conference on Computer Vision and Pattern Recognition (CVPR)**：这是一场在计算机视觉和模式识别领域具有重要影响力的会议，每年都会展示这个领域的最新研究成果。
7. IJCV
8. ICCV每2年举办一次，与CVPR、ECCV并称计算机视觉三大顶级会议
9. **Association for Computational Linguistics (ACL)**：这是一场在计算语言学和自然语言处理领域具有重要影响力的会议，每年都会展示这个领域的最新研究成果。
## 如何进行文献检索？
### 1. 确定研究主题
- **细化关键词**：根据研究主题，列出相关的关键词和短语。这些关键词将用于数据库搜索。
### 2. 选择合适的数据库

- **学术数据库**：常用的学术数据库包括IEEE Xplore, ACM Digital Library, ScienceDirect, SpringerLink, Google Scholar等。这些数据库覆盖了计算机科学与技术领域的广泛文献。
### 3. 使用关键词搜索，使用筛选搜索

### 4. 评估文献质量
- **阅读全文**：对于初步筛选出的文献，阅读全文以评估其对研究主题的贡献和质量。
- **引用和影响因子**：考虑文献的引用次数和期刊的影响因子，这些通常是衡量文献质量的指标。
### 5. 管理检索到的文献
- **记录信息**：记录每篇文献的详细信息，如作者、标题、出版年份、期刊名称等，以便后续引用。
- **使用文献管理工具**：使用如EndNote, Zotero, Mendeley等文献管理工具来组织和管理文献。
## 梯度下降法？
梯度下降法的基本思想是：通过计算目标函数关于参数的梯度（即导数），然后沿着梯度的反方向更新参数，以此来逐步接近函数的最小值。梯度的方向是函数增长最快的方向，因此，沿着梯度的反方向移动，可以使得函数值下降。
- **批量梯度下降（Batch Gradient Descent）**：每次更新使用所有训练样本的梯度。
    
- **随机梯度下降（Stochastic Gradient Descent, SGD）**：每次更新只使用一个训练样本的梯度。
    
- **小批量梯度下降（Mini-batch Gradient Descent）**：每次更新使用一小部分训练样本的梯度，这是最常用的形式。
## 介绍一下牛顿迭代是什么；
牛顿迭代法是一种用于求解方程的迭代数值方法。它基于以下思想：通过使用切线逼近曲线，找到函数的根。
1. 先猜测一个初始值 x₀；  
2. 在函数 f(x) 上找到点 (x₀, f(x₀)) 处的切线；  
3. 切线与 x 轴的交点作为新的猜测值 x₁；  
4. 重复步骤2和步骤3，直到满足所需的精度或达到最大迭代次数


# Meta-Learning - 元学习

- Meta Learning希望使得模型获取一种“学会学习”的能力，使其可以在获取已有“知识”的基础上快速学习新的任务
	- 使Alpha-go快速学会下象棋
	- 使小猫图片分类器，快速具有分类其他物体的能力
- 其内核区别于**迁移学习 (Transfer Learning)**！
![550](https://i-blog.csdnimg.cn/blog_migrate/a3697584eaa6f2f18db1c6589a4fca69.jpeg)

## MAML过程

[meta-learning（元学习）是什么？-CSDN博客](https://blog.csdn.net/weixin_43135178/article/details/126531317)

## 区别辨析

1. MAML的执行过程与model pretraining & transfer learning的区别是什么？
	- meta learning的L是**第二次更新的梯度方向**
	- model pretraining的L来源于**同一个model的参数**（只有一个），使用训练数据计算的loss和梯度对model进行更新
	![](https://i-blog.csdnimg.cn/blog_migrate/de84d14519e9a655b5b5485eadf6abf8.jpeg)
	- meta learning最小化每一个子任务训练一步之后，第二次计算出的loss，用第二步的gradient更新meta网络，这代表了什么呢？子任务从【状态0】，到【状态1】，我们希望状态1的loss小，说明meta learning更care的是**初始化参数未来的潜力**。

2. 在更新训练任务的网络时，只走了一步，然后更新meta网络。为什么是一步，可以是多步吗？
	- 只更新一次，速度比较快；因为meta learning中，子任务有很多，都更新很多次，训练时间比较久。
	- MAML希望得到的初始化参数在新的任务中finetuning的时候效果好。如果只更新一次，就可以在新任务上获取很好的表现。把这件事情当成目标，可以使得meta网络参数训练是很好（目标与需求一致）。
	- 当初始化参数应用到具体的任务中时，也可以finetuning很多次。
	- Few-shot learning往往数据较少。
	那么MAML中的训练任务的网络可以更新多次后，再更新meta网络吗？

我觉得可以。直观上感觉，更新次数决定了子任务对于meta网络的影响程度，我觉得这个步数可以作为一个参数来调。
# Knowledge Graphs - 知识图谱

# Reinforcement Learning - 强化学习

