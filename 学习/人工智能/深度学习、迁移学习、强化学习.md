# 1. 深度学习

### 深度学习一般指的是，基于卷积神经网络的深度学习。使用这些深度神经网络（如 CNN、RNN 等），解决图像、文本、语音等领域，其中的分类、回归问题。

## 关键词
- CNN、RNN
# 2. 迁移学习

### 一般来说，迁移学习用于某些所能收集到的数据量小的领域。可以复用现有领域知识，不用再花费很大的代价去重新采集和标记庞大的新数据集（可能根本就无法获取到），对于新出现的领域可以快速地迁移和应用。
![[Pasted image 20231028113040.png]]

## 为什么需要迁移学习

1. （标注不足）**数据与少标注的矛盾**：虽然有大量的数据，但往往都是没有标注的，无法训练机器学习模型。人工进行数据标定太耗时。
2. （算力不足）**大数据与弱计算的矛盾**：普通人无法拥有庞大的数据量与计算资源。因此需要借助于模型的迁移。
3. （泛化）**普适化模型与个性化需求的矛盾**：即使是在同一个任务上，一个模型也往往难以满足每个人的个性化需求，比如特定的隐私设置。这就需要在不同人之间做模型的适配。
4. **特定应用（如冷启动）的需求**
	- **冷启动**和**热启动**：冷启动就是缺乏历史数据，无法解决新的业务；热启动就是已经有足够的历史数据，有效地解决业务问题。
	- 热启动通常更容易，有足够的数据来支持推荐算法的运行。

## 迁移学习的要解决的基本问题
- 如何进行迁移？
- 给定目标领域，如何选择一个合适的源领域进行迁移？
- 什么时候适合进行迁移，什么情况不合适？

## 和传统机器学习的区别
![](https://pic4.zhimg.com/80/v2-34251c4fc8a9572915b81a4c3c8f3e0b_720w.webp)


## 关键词
- 域 Domain，学习的主体，由数据和其概率分布构成，源域 Source Domain、目标域 Target Domain
	- 按照目标域的分类：监督、半监督、无监督，少标签或无标签的后两个，是研究的重点，这里的标签指的是目标域上的
- 任务 Task，标签和其对应的函数
- 同构迁移学习 Homogeneous TL，异构迁移学习 Heterogeneous TL
- 归纳式 Inductive：源域和目标域的学习任务不同；直推式 Transductive：域不同，学习任务相同；无监督 Unsupervised：源域和目标域都没有标签
- 基于样本的迁移 Instance Based
- ![](https://pic2.zhimg.com/80/v2-780908399cc9de263e7e1b1e27fee479_720w.webp)
- fine-tune：微调，利用已经训练好的网络，针对自己的任务进行调整。
- GAN：Generative Adversarial Network，生成对抗网络，分为 生成网络/生成器 和 判别网络/判别器
- 领域自适应：Domain Adaptation，见下
- 特征融合：见下
- 自注意力机制：模仿人的注意力（对焦点投入更多资源，抑制其他无关信息），深度学习中的注意力是，从众多信息中选择出对当前任务目标更关键的信息，对其进行加权。

## 领域自适应

- 目标是：利用有标记的数据 Ds 去学习一个分类器，来预测目标域 Dt 的标签 yt
- 有标记的源域 Ds，无标记的目标域 Dt，两个领域的数据分布不同，标签空间相同，条件概率分布相同（简化问题）
- 方法：基于特征的适应、基于样本的适应、基于模型的适应、基于差异匹配、基于对抗学习
## 特征融合

- 指的是在给定不同属性的特征时，利用特征之间的互补性（差异性），融合特征之间的优点，进而提高模型的性能
- 技术分类
	- 前端融合：在输入层上做融合，先融合多层特征，再在融合后的特征上训练
	- 中间融合：将不同的特征，转成中间结果，再融合
	- 后端融合：在预测层上做融合
- 具体的技术：特征拼接、特征求和（均值、pooling、加权求和）、特征之间对应元素相乘、特征之间求外积+展开之后过MLP、跳跃连接（skip）······
## 视觉转换器 ViT

- 视觉转换器（Vision Transformer，ViT）是一种深度学习模型架构，它在计算机视觉领域中被广泛使用。ViT模型最早由Google Brain的研究人员于2020年提出。与传统的卷积神经网络（CNN）不同，ViT使用自注意力机制来处理图像数据。它将输入的图像分成一系列的小块，然后将这些小块变换为序列数据，以便模型可以使用自注意力机制来捕捉不同区域之间的关系。
- ViT的核心思想是将图像数据转化为序列数据，然后使用自注意力机制来学习图像中的各个元素之间的关联。这种方法在某些任务上表现出色，例如图像分类、目标检测和分割等。

## Fine-Tuning 微调

- 机器学习中的一种常见技术，用于调整预训练模型以适应特定任务。它通常涉及采用一个已经在大规模数据上训练过的模型，然后在目标任务的小规模数据集上进一步训练模型，以提高模型在特定任务上的性能。
- 微调通常涉及以下步骤：
	1. 预训练：首先，使用大规模的数据集（通常是通用数据集，如维基百科文本或大规模图像数据集）来预训练一个深度学习模型，例如BERT（自然语言处理）或ResNet（计算机视觉）。
	2. 微调层：然后，针对特定任务的小规模数据集，例如情感分类或目标检测，将模型的一些层（通常是顶层或分类层）进行微调。这意味着在这些层中**更新权重和参数**，以使模型能够更好地适应目标任务。   
	3. 目标任务训练：在微调过程中，模型在特定任务的数据上进行进一步训练，以适应任务的要求。这可以通过降低学习率、调整权重等方式来实现。

# 3. 强化学习

### 让机器人有“自我探索”和“自我思考”的能力。
其特点是：
- 通过不断地试错来改进
- 本身没有 Label （不同于监督学习，每一步都有 True or False）
- 基本是以闭环的形式
- 不会直接指示哪种行动 action，一系列的 action 和奖励信号 reward signals 都会影响比较长的时间

## 关键词
- GoogleDeepMind，DQN
- Agent，Envirenment，State，Action，Rewards
- 马尔可夫决策过程

## 强化学习模型

0. 智能 Agent 根据当前的环境 Environment 做出一个决策 Action，该决策影响环境，达到一个新的 State，得到一个反馈 Reward，Agent 再这样循环。这就是一个马尔可夫决策过程。
1. 未来奖励系数。马尔科夫假设：当前状态只由上一个状态和行为所决定，和前序的更多状态无关。智能体只需考虑在当下做出一个使未来收益最大化的决定。
	- 但是实际上未来是不确定的，那么需要乘一个系数gamma∈(0, 1)。
2. Q-Learning。Q(s, a) 函数。贝尔曼公式。
3. Deep Q Learning（DQN）。融合神经网络和Q-Leaning的方法。在这里，神经网络的作用是，分析 Q(s, a) 函数，使用神经网络来生成 Q 值，因为如果使用表格存储的话，太消耗内存和搜索时间了。

## 监督学习、无监督学习、强化学习

### 无监督学习能自学习映射关系。

## 多任务学习

### 在相关任务间共享表示信息，使模型在原始任务上泛化地更好