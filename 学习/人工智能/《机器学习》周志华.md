# 第一章 绪论
- 数据决定模型的效果的上限，算法则是让模型无限逼近上限
- 假设空间和版本空间

# 第二章 模型评估与选择
## 2.2 评估方法
- 留出法
- 分层采样：保留类别比例
- 交叉验证法：k折交叉验证，10次10折交叉验证法
- 留一法
- bootstrap 自助法：
	- 自助采样(bootstrap sampling)
## 2.3 性能度量
### 回归任务
- 均方误差(Mean Squared Error, MSE)
### 分类任务
- 查准率(precision)和查全率(recall)
	- 查准率和查全率是一对矛盾的度量
	- 可以画出P-R曲线，如果一个PR曲线完全包住了另一个曲线，那么前者性能更优；若有交叉，则不能直接断言，因此通常用“平衡点 ”(Break-Even Point, BEP)，也就是P=R的这条射线，和曲线的交点，来判断不同模型的性能
	- 也可以用F1度量
- 宏P、R、F1
- 微P、R、F1
- ROC(Receiver Operating Characteristic，受试者工作特征)
	- 横轴为假正例率，纵轴为真正例率
- AUC(Area Under ROC Curve)
	- 即ROC曲线下各部分面积求和而得
- 代价敏感错误率与错误曲线

## 2.4 比较检验
## 2.5 偏差与方差
- **“偏差-方差分解”** 是解释学习算法泛化性能的一种重要工具。zui
- 根据推导，泛化误差 = 偏差 + 方差 + 噪声
- **偏差**度量了学习算法的期望预测与真实结果的偏离程度，也就是学习算法本身的拟合能力
- **方差**度量了同样大小的训练集变动导致的学习性能变化，刻画了数据扰动造成的影响
- **噪声**表达了当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度
- 一般来说，偏差与方差有冲突，称为**偏差-方差窘境(bias-variance dilemma)** 
	- 训练不足时，学习器拟合能力弱，偏差占主导
	- 训练充足时，训练数据的轻微扰动可能导致学习器变化很大，容易发生过拟合，方差占主导

# 第三章 线性模型
## 3.2 线性回归

- 线性回归：实际上就是求解w和b使 $E_{(w, b)}=\sum_{i=1}^m\left(y_i-w x_i-b\right)^2$ 最小化的过程
- 均方误差：对应了“欧氏距离”
- 对数线性回归：$\ln y=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b$ 
- 广义线性模型：$y=g^{-1}\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right)$ 
### 最小二乘法
- 基于均方误差最小化，来进行模型求解的方法称为“最小二乘法”
- 在线性回归中，最小二乘法就是找到一条直线，使所有样本到直线上的欧式距离之和最小
### 多元线性回归

若使：
$$
\mathbf{X}=\left(\begin{array}{ccccc}
x_{11} & x_{12} & \ldots & x_{1 d} & 1 \\
x_{21} & x_{22} & \ldots & x_{2 d} & 1 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
x_{m 1} & x_{m 2} & \ldots & x_{m d} & 1
\end{array}\right)=\left(\begin{array}{cc}
\boldsymbol{x}_1^{\mathrm{T}} & 1 \\
\boldsymbol{x}_2^{\mathrm{T}} & 1 \\
\vdots & \vdots \\
\boldsymbol{x}_m^{\mathrm{T}} & 1
\end{array}\right)
$$

$$
\hat{\boldsymbol{w}}=(\boldsymbol{w} ; b)
$$
则有：
$$
\hat{\boldsymbol{w}}^*=\underset{\hat{\boldsymbol{w}}}{\arg \min }(\boldsymbol{y}-\mathbf{X} \hat{\boldsymbol{w}})^{\mathrm{T}}(\boldsymbol{y}-\mathbf{X} \hat{\boldsymbol{w}}) .
$$
## 3.3 对数几率回归
$$
y=\frac{1}{1+e^{-\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right)}} .
$$
## 3.4 线性判别分析
## 3.5 多分类学习
- OvO, One vs. one
- OvR, One vs. Rest
- MvM, Many vs. Many
## 3.6 类别不平衡问题
- 无偏采样：意味着真实样本的类别比例在训练集中得以保持
- 再缩放/再平衡（基于“训练集是真实样本的无偏估计”）
- 主流三类做法：欠采样、过采样、阈值移动
- 过采样方法：
	- 不能简单地对初始正例样本进行重复采样
	- SMOTE：插值
- 欠采样方法：
	- 若随机丢弃，可能丢失重要信息
	- EasyhEnsemble：集成学习，反例划分不同集合

# 第四章 决策树
- 递归返回情形：
	1. 当前结点样本全属于同一类别，无需划分
	2. 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分
	3. 当前结点样本集合为空，不能划分
- 决策树的关键是如何**选择最优划分属性**
## 4.2 划分选择
### 信息增益划分 - ID3

- 信息熵：$\operatorname{Ent}(D)=-\sum_{k=1}^{|\mathcal{Y}|} p_k \log _2 p_k$ 
	- 取值范围0~log2|y|。y为类别数
	- 值越小，说明样本集合D的纯度越高
- **信息增益（互信息）**：
$$\operatorname{Gain}(D, a)=\operatorname{Ent}(D)-\sum_{v=1}^V \frac{\left|D^v\right|}{|D|} \operatorname{Ent}\left(D^v\right)\tag{4.2}$$ 
	- 已知属性a的取值后，样本类别这个随机变量的不确定性减小的程度
	- 信息增益越大，说明样本不确定性减小程度越大

### 增益率划分 - C4.5

- **信息增益会对可取值数目较多的属性有所偏好**，为了减少影响，C4.5决策树算法使用“增益率”（gain ratio）来选择最优划分属性
- 增益率：
$$\operatorname{Gain\_ ratio}(D,a)=\frac{\operatorname{Gain}(D, a)}{\operatorname{IV}(a)}\tag{4.3}$$
$$\operatorname{IV}(a)=-\sum_{v=1}^{V}\frac{|D^v|}{D}log_2\frac{|D^v|}{D}\tag{4.4}$$
	- IV为属性a的固有之，属性a下取值数目越多（V越大），则IV值通常越大
	- 增益率对取值数较少的属性有所偏好
	- 因此往往先从候选划分属性中，找到信息增益高于平均的属性，再从中选取增益率最高的

### 基尼指数 - CART

- CART(Classfication and Regression Tree)，分类和回归任务都可以使用。用“基尼系数”(Gini index)
- 数据集D的纯度可以用基尼值来度量
$$
\begin{aligned}
\operatorname{Gini}(D) & =\sum_{k=1}^{|\mathcal{Y}|} \sum_{k^{\prime} \neq k} p_k p_{k^{\prime}} \\
& =1-\sum_{k=1}^{|\mathcal{Y}|} p_k^2 .
\end{aligned}
$$
	- 直观来说，反映了从数据集D中随机抽取两个样本，类别标记不一样的概率。值越小，纯度越高。
	- 最终选择使得划分后基尼指数最小的属性作为最优
- 属性a的基尼指数
$$
\operatorname{Gini} \operatorname{index}(D, a)=\sum_{v=1}^V \frac{\left|D^v\right|}{|D|} \operatorname{Gini}\left(D^v\right)
$$

## 4.3 剪枝
- 防止决策树**过拟合**的主要手段。训练过程中，为了尽可能正确分类训练样本呢，可能导致分支过多，造成拟合
- 基本策略：预剪枝和后剪枝

## 4.4 连续与缺失值
### 连续值处理
- 可以采用二分方法，采用区间的中位点作为候选划分点，然后可以公式$(4.2)$

缺失值处理
- 要解决两个问题
1. 如何在属性值缺失的情况下进行划分属性？
2. 给定划分属性，若样本在该属性上值缺失，如何划分？

# 第五章 神经网络
- 标准BP算法和累积BP算法的区别 类似于 SGD和标准梯度下降的区别
- 缓解过拟合的策略
	- 早停
	- 正则化：在误差目标函数中增加一个用于描述网络复杂度的部分
- 跳出局部最小的方法
	- 多组初始化值进行分别训练
	- 模拟退火
	- 随机梯度下降
	- 遗传算法


# 第六章 支持向量机

## 6.1 间隔与支持向量

- 划分超平面: 
$$\boldsymbol{w}^\mathrm {T}\boldsymbol{x} + b = 0\tag{6.1}$$
- 样本点 x 到超平面的距离:
$$
r=\frac{\left|\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right|}{\|\boldsymbol{w}\|}\tag{6.2}
$$
- 距离超平面最近的几个训练样本点，称为**支持向量**，两个**不同类支持向量**到超平面的距离之和，被称为 **间隔** (margin)，为：
$$\gamma=\frac{2}{||\boldsymbol{w}||}\tag{6.4}$$
- 显然我们要求最大化 $\frac{2}{||w||}$，等价于最小化 $||w||^2$，于是，可以改为求：
$$
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2}\|\boldsymbol{w}\|^2 \\
\text { s.t. } & y_i\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_i+b\right) \geqslant 1, \quad i=1,2, \ldots, m
\tag{6.6}\end{array}
$$

- **间隔**从表达式上来说仅与 $w$ 有关，但实际上 $b$ 通过约束隐式影响 $w$ 的取值，进而影响间隔

## 6.2 对偶问题

- 希望求解$(6.6)$来得到模型
$$
f(\boldsymbol{x})=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\tag{6.7}
$$

- 对式(6.6)使用拉格朗日乘子法可得到其“对偶问题”(dual problem)，然后求解其对偶问题即可

## 6.3 核函数

- 前面一直都假设训练样本是线性可分的，实际任务中，可能需要将样本从原始空间**映射到更高维的特征空间**，使在高维空间线性可分
- 更多见正文

## 6.4 软间隔与正则化

- 我们一直假定训练样本在样本空间或特征空间中是线性 可分的，即存在一个超平面能将不同类的样本完全划分开，而实际上可能
	- 很难确定合适的核函数
	- 是否是过拟合导致的
- 如何解决？
	- 引入“**软间隔**”，允许某些样本不满足约束

## 6.5 支持向量回归

## 6.6 核方法


# 第七章 贝叶斯分类器

## 7.1 贝叶斯决策论

# 第八章 集成学习

- 基本上是通过多个体学习器和一个结合模块产生输出。可能是同质(homogeneous)的，也可能是异质(heterogeneous)的

## 8.1 个体与集成

- 集成学习：通过构建并结合多个学习器来完成学习任务
- 集成学习通过将多个学习器结合，可以获得比单一学习器显著优越的泛化性能
	- 对“弱学习器”比较明显

- **二分类问题，当超半数基分类器正确，集成分类正确，此时随个体分类器数量增大，继承错误率将指数下降趋向为0。**
	- 但是关键假设是 **个体学习器的误差相互独立**
## 8.2 Boosting - 串行优化

- 个体学习器间存在强依赖关系、必须串行生成的序列化方法
- 先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注, 然后基于调整后的样本分布来训练下一个基学习器
- 主要关注**降低偏差**，基于泛化性能相当弱的学习器构建出很强的集成
- Boosting 从优化角度来看，是用 forward-stagewise 这**种贪心法去最小化损失函数，由于采取的是串行优化的策略，各子模型之间是强相关的，于是子模型之和并不能显著降低方差**。所以说 boosting 主要还是靠降低偏差来提升预测精度
### AdaBoost

 - Adaboosting 算法是一种迭代算法，其核心思想是针对同一个训练集训练不同的弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。
 - 算法本身是通过改变数据分布来实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。总的原则是“增大错误样本的权重，减小正确样本的权重"

## 8.3 Bagging 和 随机森林 - 并行优化

- 个体学习器间不存在强依赖关系、可同时生成的并行化方法；
- 若希望得到泛化性能强的集成，则个体学习器应尽可能独立；虽然无法做到完全独立，可以使其有较大差异；考虑采用相互有交叠的采样子集

### Bagging
- 来源于 Bootstrap AGGregatING
- 可采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合
	- 预测输出时，对分类任务简单投票，对回归任务简单平均
- 主要关注**降低方差**，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效用更为明显.
- Bagging 算法是对训练样本进行采样，产生出若干不同的子集，**再从每个数据子集中训练出一个分类器，取这些分类器的平均，所以是降低模型的方差(variance)。** Bagging 算法和 RandomForest 这种并行算法都有这个效果

### 随机森林 Random Forest
- 传统决策树在选择划分属性时，是在当前节点的**所有属性**中选一个最优属性；而RF中，则是从属性集合中选出一个**包含k个属性的子集**，再从子集中选出一个最优属性用于划分。
	- k=1，就是随机选择一个属性；推荐值为 $k=log_2d$ 
- 比起bagging，多样性不仅来自**样本扰动**，还来自**属性扰动**，使泛化性能进一步增强

# 第九章 聚类

- Unsupervised Learning 中研究做多的任务是聚类；常见的还有密度估计、异常检测等

## 9.1 聚类任务

聚类任务的两个基本问题：性能度量 和 距离计算

## 9.2 性能度量

一种“有效性指标”，一方面可以用来评估好坏，另一方面可以用来作为优化目标。
- 要求 簇内相似度高，簇间相似度低

度量分为两类。
- 外部指标：与某“参考模型”比较
- 内部指标：直接利用聚类的结果
$$
\begin{aligned}
& \left.a=|S S|, \quad S S=\left\{\left(x_i, x_j\right) \mid \lambda_i=\lambda_j, \lambda_i^*=\lambda_j^*, i<j\right)\right\} \\
& \left.b=|S D|, \quad S D=\left\{\left(x_i, x_j\right) \mid \lambda_i=\lambda_j, \lambda_i^* \neq \lambda_j^*, i<j\right)\right\} \\
& \left.c=|D S|, \quad D S=\left\{\left(x_i, x_j\right) \mid \lambda_i \neq \lambda_j, \lambda_i^*=\lambda_j^*, i<j\right)\right\} \\
& \left.d=|D D|, \quad D D=\left\{\left(x_i, x_j\right) \mid \lambda_i \neq \lambda_j, \lambda_i^* \neq \lambda_j^*, i<j\right)\right\}
\end{aligned}
$$
通过聚类得到的划分为$C$，参考模型给出划分为$C^*$
- SS：C中相同，$C^*$中也相同
- SD：C中相同，$C^*$不同
- DS：C中不同，$C^*$相同
- DD：C中不同，$C^*$也不同
- $a+b+c+d=m(m-1)/2$

- Jaccard系数, JC
$$
\mathrm{JC}=\frac{a}{a+b+c}\tag{9.5}
$$
- FM指数, FMI
$$
\mathrm{FMI}=\sqrt{\frac{a}{a+b} \cdot \frac{a}{a+c}}\tag{9.6}
$$
- Rand指数, RI
$$
RI = \frac{2(a+d)}{m(m-1)}
$$
- 这些指标都是$[0,1]$区间，值越大越好

$$
\begin{aligned}
&\begin{aligned}
\operatorname{avg}(C) & =\frac{2}{|C|(|C|-1)} \sum_{1 \leqslant i<j \leqslant|C|} \operatorname{dist}\left(x_i, x_j\right), \\
\operatorname{diam}(C) & =\max _{1 \leqslant i<j \leqslant|C|} \operatorname{dist}\left(x_i, x_j\right), \\
d_{\min }\left(C_i, C_j\right) & =\min _{x_i \in C_i, x_j \in C_j} \operatorname{dist}\left(x_i, x_j\right), \\
d_{\operatorname{cen}}\left(C_i, C_j\right) & =\operatorname{dist}\left(\boldsymbol{\mu}_i, \boldsymbol{\mu}_j\right)
\end{aligned}\\
\end{aligned}
$$

- 其中，$dist(\cdot,\cdot)$用于计算两个样本之间的距离
- $d_{cen}(C_i,C_j)$对应于两个簇之间的中心点距离

- DB指数, DBI
$$
\mathrm{DBI}=\frac{1}{k} \sum_{i=1}^k \max _{j \neq
i}\left(\frac{\operatorname{avg}\left(C_i\right)+\operatorname{avg}\left(C_j\right)}{d_{\operatorname{cen}}\left(\boldsymbol{\mu}_i, \boldsymbol{\mu}_j\right)}\right)\tag{9.12}
$$

- 它计算的是每个**聚类与其最相似聚类之间的平均相似度**。
- DBI值越小，表示聚类结果越好，即聚类内部紧密度高且聚类间分离度好。

- Dunn指数, DI
$$
\mathrm{DI}=\min _{1 \leqslant i \leqslant k}\left\{\min _{j \neq i}\left(\frac{d_{\min }\left(C_i, C_j\right)}{\max _{1 \leqslant l \leqslant k} \operatorname{diam}\left(C_l\right)}\right)\right\} \\
\tag {9.13}
$$
- DI指数衡量的是聚类结果的分离度和紧密度。
- 它计算的是**所有聚类中最小簇间距离与最大簇内距离的比值**。DI值越大，表示聚类结果越好，即聚类间分离度高且聚类内部紧密度好。

## 9.3 距离计算

- 最常用的距离 “闵可夫斯基距离”(Minkowski distance)
$$
\operatorname{dist}_{\mathrm{mk}}\left(x_i, x_j\right)=\left(\sum_{u=1}^n\left|x_{i u}-x_{j u}\right|^p\right)^{\frac{1}{p}}\tag{9.18}
$$
- $p=1$ 时，曼哈顿距离
- $p=2$ 时，欧氏距离

- VDM用于无序属性距离计算，第i个样本簇，取值为a/b，属性u
	- 通过计算不同属性值在不同类别中的分布差异来量化这些属性值之间的差异
$$
\begin{aligned}
&\operatorname{VDM}_p(a, b)=\sum_{i=1}^k\left|\frac{m_{u, a, i}}{m_{u, a}}-\frac{m_{u, b, i}}{m_{u, b}}\right|^p\\
\end{aligned}\tag{9.21}
$$

- 可以用Minkowski距离和VDM距离结合起来，处理混合属性
- 不同属性重要不同，则可以进行加权

## 9.4 原型聚类

“基于原型的聚类”，假设聚类能通过一组原型刻画，初始化原型，然后对原型进行迭代更新求解。

### k均值 k-means

最小化平方误差：
$$
E=\sum_{i=1}^k \sum_{x \in C_i}\left\|x-\mu_i\right\|_2^2\tag{9.24}
$$
其中 $\boldsymbol{\mu}_i=\frac{1}{\left|C_i\right|} \sum_{\boldsymbol{x} \in C_i} \boldsymbol{x}$ 是簇 $C_i$ 的均值向量。
- 直观上反映了对所有簇，簇内样本围绕均值的紧密程度。
- 这是一个NP难问题
- 采用贪心算法，通过迭代求近似解
	1. 选择 k 个样本为初始均值向量
	2. 每次计算样本与所有均值向量的距离，划入最小的类
	3. 计算新均值向量
	4. 不变则结束，变则继续更新


### 学习向量量化 - LVQ

数据带有类别标记，利用样本的监督信息来辅助聚类。
- 每个样本向量由 $n$ 个属性描述
- 目标是学习到一组 $n$ 维原型向量 ${p_1,p_2,\dots,p_q}$ 每个原型向量代表一个聚类簇
	1. 初始化一组原型向量 ${p_1,p_2,\dots,p_q}$ 
	2. 每次计算样本与原型的距离，找到最近的原型 $p_i*$ ，若样本与原型标记相同，则原型向样本移动一部分，否则远离一部分
	3. 反复直到满足特定条件

- Voronoi剖分
	- 学习到一组 $n$ 维原型向量 ${p_1,p_2,\dots,p_q}$ 后，对任意样本，将划入与其最近的簇中，可划分出边界


### 高斯混合聚类


## 9.5 密度聚类

### DBSCAN

一种著名的密度聚类算法。通过“邻域”参数 $(\epsilon, MinPts)$ 刻画，可以得到以下概念：
- $\epsilon$-邻域
- 核心对象
- 密度直达、密度可达、密度相连

基于此，簇定义为 `由密度可达关系导出的最大的密度相连的样本合集`。

如何找到这样的簇？实际上，从 $x$ 密度可达的所有样本即可组成一个簇（同时满足**连接性、最大性**）。
1. 任选一个核心对象为种子，确定簇
2. 直到所有核心对象均被访问
3. 不属于任何簇的被认为是“噪声”或”异常“ (noise, anomaly)

## 9.6 层次聚类

试图在不同层次对数据集进行划分，形成树形聚类结构

### AGNES

1. 将每个样本看作初始聚类簇
2. 每一步找出距离最近的两个聚类簇进行合并
3. 不断重复直到设定值

- 聚类簇距离可以用 $d_{min}$、$d_{max}$、$d_{avg}$ 计算，

# 第十章 降维与度量学习

## 10.1 k近邻学习 - kNN

k-Nearest Neighbor, 常用的监督学习方法。
- 给定测试样本，基于某种距离度量找出训练集中与其最靠近的 $k$ 个训练样本
- 基于这 $k$ 个样本的信息来预测
	- 分类任务中使用“投票法“
	- 回归任务中使用”平均法“

- 这是一种 **”懒惰学习“**，在训练阶段仅仅把样本保存起来，而不进行其他处理；对应的为 **“急切学习”**

## 10.2 低维嵌入

上面的讨论基于一个重要假设：测试样本附近小距离 $\delta$ 内，能够找到一个训练样本。要求训练样本的采样密度足够大，实现“密采样”。
- 实际上在现实任务中很难满足。
- 尤其是当维数很高时

**“维数灾难” (curse of dimensionality)** 指的就是高维情形下，数据样本稀疏、距离计算困难的情景

**“降维” (dimension reduction)** 来缓解。数据样本是高维的，但与学习任务密切相关的可能是一个低维分布，或 **"嵌入" (embedding)** 。

一般来说，若想获得低维子空间，最简单的方法是对原始高维空间进行**线性变换**。

**评估降维效果**通常是比较将为前后学习器的性能。也可以用二维三维可视化技术进行判断。

### 多维缩放 - MDS

要求原始空间中样本之间的**相对距离在低维空间中保持**的降维方法。

## 10.3 主成分分析 - PCA

Principal Component Analysis，主成分分析。

考虑：对于正交属性空间中的样本点，如何用一个超平面（直线的高维推广），对所有样本进行恰当的表达？同时超平面应该具有：
- **最近重构性**：样本点到超平面足够近
- **最大可分性**：样本点在超平面上投影尽可能分开

算法过程：
1. 所有样本进行中心化
2. 计算样本的协方差矩阵
3. 对协方差矩阵进行特征值分解
4. 取最大的 $d^\prime$ 个特征值所对应的特征向量（也就是投影矩阵）

维数 $d^\prime$ 指定，或用其他学习器验证。也可以设置阈值，选取使下式成立的最小 $d^\prime$ 值
$$
\frac{\sum_{i=1}^{d^{\prime}} \lambda_i}{\sum_{i=1}^d \lambda_i} \geqslant t
$$

## 10.6 度量学习

在机器学习中，对高维数据进行降维的主要目的是希望找到一个合适的低维空间，在此空间中进行学习能比原始空间性能更好。
事实上，每个空间对应了在样本属性上定义的一个距离度量，而寻找合适的空间，实质上就是在寻找一 个合适的距离度量。

直接尝试“学习”出一个合适的距离度量呢？这就是度量学习 (metric learning)的基本动机。


# 第十四章 概率图模型

概率图模型是一类用图来表达变量相关关系的概率模型。
常用一个结点表示一个或一组随机变量，边表示变量间的概率相关关系，即“变量关系图”。

用有向无环图表示，称为“有向图模型”或“贝叶斯网”。用无向图表示，称为“无向图模型”或“马尔可夫网”。

## 14.1 隐马尔可夫模型 - HMM

Hidden Markov Model，结构最简单的动态贝叶斯网。

- 马尔可夫链：系统下一个时刻的状态仅仅由当前状态决定，不依赖以往的任何状态

确定一个隐马尔可夫模型，除了结构外还需要三组参数：
1. 状态转移概率。模型在各个隐状态之间转换的概率，记为矩阵 $A = [a_{ij}]_{N\times N}$ 
2. 输出观测概率。模型根据隐状态获得观测值的概率，记为矩阵 $B = [a_{ij}]_{N\times M}$ 
3. 初始状态概率。模型在初始时刻各状态出现的概率，记为 $\pi=(\pi_1,\pi_2,\dots,\pi_N)$ 

按照如下过程产生观测序列：
1. 根据初始状态概率 $\pi$ 选择初始状态 $y_1$
2. 根据状态 $y_t$ 和输出观测概率 $B$ 确定观测变量 $x_t$
3. 根据状态 $y_t$ 和状态转移矩阵 $A$ 确定 $y_{t+1}$ 
4. 根据条件终止或继续

隐马尔可夫模型的三个基本问题：
1. 如何评估模型与观测序列的匹配程度？
2. 如何根据观测序列推断出隐藏的模型状态？
3. 如何训练模型使其能够最好地描述观测数据？

## 14.2 马尔可夫随机场 - MRK

Markov Random Field, 典型的马尔可夫网，无向图模型。



# 第十五章 规则学习

指的是从训练数据中学习出一组能用于对未见示例进行判别的规则。

形式化看，一条规则形如：
$$
\oplus \leftarrow \mathbf{f}_1 \wedge \mathbf{f}_2 \wedge \cdots \wedge \mathbf{f}_L\tag{15.1}
$$

- 冲突：当同一个示例可以被**判定结果不同**的多条规则覆盖
- 冲突消解：解决冲突的方法，投票法、排序法、元规则法
	- 元规则法：事先设定一些关于规则的规则
- 默认规则：当所有规则也不能覆盖未见示例，则用于处理

从形式语言的表达能力来看，规则分为“命题规则”和“一阶规则”。
- 命题规则：由原子命题、逻辑连接词（与、或、非、蕴含）构成
- 一阶规则：加入量词

## 15.2 序贯覆盖

规则学习的目标是**产生能覆盖尽可能多样例**的规则集。

序贯覆盖是最直接的做法，也就是逐条归纳，训练集上每学一条规则，就将该规则覆盖的训练样例去除，然后剩下的训练样例继续重复。



# 第十六章 强化学习

强化学习任务通常使用马尔可夫决策过程 (Markov Decision Process, MDP)来描述：环境 $E$ , 状态空间 $X$ , 机器动作空间 $A$ , 潜在转移函数 $P$ , 奖励函数 $R$ .

机器要学习的是通过在环境中不断尝试而学得一个”策略“，根据策略，在状态下得知要执行的动作。策略的优劣取决于长期执行这一策略后得到的累积奖励。

长期累积奖励的计算方式：
- $T$ 步累积奖励
- $\gamma$ 折扣累积奖励

强化学习中并没有监督学习中的“示例-标记”对，无法直接指导机器在状态下执行什么操作，只有等到最终结果才能通过“反思”之前的动作进行学习。

类似一种“延迟标记信息”的监督学习问题。

## 16.2 K-摇臂赌博机

最简单的情景：最大化单步奖励。仍然与监督学习显著不同，因为机器学要通过尝试来发现各个动作的结果。

- ”K-摇臂赌博机“：有K个摇臂，赌徒在投入一个硬币后可以按下其中一个摇臂，每个摇臂以一定概率吐出硬币。
- “仅探索”策略：所有尝试机会平均分给每个摇臂，最后以计算每个摇臂的吐币期望
- ”仅利用“策略：每次都按下目前为止奖赏最大的摇臂。

“探索-利用窘境“ (Exploration-Exploitation dilemma)：如果想要累积奖励最大，必须在探索和利用之间达成折中

进行n-1次尝试后，平均奖赏：
$$
Q_n(k)=Q_{n-1}(k)+\frac{1}{n}\left(v_n-Q_{n-1}(k)\right) \tag{16.3}
$$

### $\epsilon$ 贪心

每次以 $\epsilon$ 概率进行探索。

### Softmax

$$
P(k)=\frac{e^{\frac{Q(k)}{\tau}}}{\sum_{i=1}^K e^{\frac{Q(i)}{\tau}}}\tag{16.4}
$$
$\tau >0$ 称为温度，趋于 $0$ 时趋于”仅利用“，趋于无穷时趋于”仅探索“

## 16.3 有模型学习

模型已知：任务对应的马尔可夫决策过程四元组 $E = <X,A,P,R>$ 均为已知，机器已经对环境进行了建模。此时对于任意的状态转换和动作，概率是已知的，奖赏也是已知的。

有模型学习分为两个步骤，一个是**策略评估**，得到采取当前策略中的各个动作所能得到的奖赏，二是**策略改进**，根据策略评估的结果选择最优的动作。这两个步骤不停的迭代更新直到收敛，得到最优的策略。

- “策略迭代”：不断迭代策略评估和改进，直到策略收敛、不再改变为止

## 16.4 无模型学习

如果学习算法不依赖于环境建模，则称为“无模型学习” (model-free learning)，这比有模型学习要困难许多。

首先遇到的问题就是策略无法评估。

### 16.4.1 蒙特卡罗强化学习

当P和R未知，甚至有多少种状态也未知时，只能从某一状态出发，**多次采样**得到不同的状态和所能获得的奖赏，蒙特卡罗法从某一状态出发，使用某种策略采样，记录新的状态和所获得的奖赏，多次采样得到多条轨迹，在对累积奖赏求平均，得到最后的状态动作值函数。

-  **同策略蒙特卡罗法**：被评估的策略和被改进的策略都是 $\epsilon$ 贪心的算法，所以称为同策略，但是采用 $\epsilon$ 贪心的算法只是为了进行模型评估，实际上最后改进和使用的应该是非 $\epsilon$ 贪心的算法，异策略的蒙特卡罗法就是一种评估和改进的策略不同的算法。

-  **异策略蒙特卡罗法**：异策略的蒙特卡罗法是评估和改进的策略不同的算法，评估的策略采用 $\epsilon$ 贪心的算法，而改进的策略采用非 $\epsilon$ 贪心的算法，要了解异策略算法，首先要了解一个采样的概念：重要性采样。

- 重要性采样

## 16.5 值函数近似

## 16.6 模仿学习

在现实任务中，强化学习往往可以得到人类专家的决策过程范例，这就是“模仿学习” (imitation learning)。

### 16.6.1 直接模仿学习

强化学习任务中多步决策的搜索空间巨大，基于累计奖赏来学习很多步之前的合适决策非常困难，而直接模仿人类专家的“状态-动作对”可以显著缓解这一困难。

可以通过人类专家的决策轨迹数据，抽取出“状态-动作对”，用这样构造出的数据集合学习到模型策略，作为初始策略。

### 16.6.2 逆强化学习

在很多任务中，很难设计奖励函数。逆强化学习用于从人类专家提供的范例数据中反推出奖励函数。

逆强化学习的基本思想是：欲使机器做出与范例一致的行为，等价于在某个奖赏函数的环境中求解最优策略,  该最优策略所产生的轨迹与范例数据一致。

